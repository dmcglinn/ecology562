<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Lecture 12&mdash;Monday, February 6, 2012</title>
<link rel="stylesheet" type="text/css" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/green.css" title="green" /> 
<link rel="stylesheet" type="text/css" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/calendar.css" title="calendar" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/purple.css" title="purple" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/large.css" title="large" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/reverse.css" title="reverse" /> 
<!-- the @import method only works from 5.0 and upwards  -->
<!-- so, using @import would "hide" the more sophisticated sheet from < 5.0 browsers -->
<!-- <style type="text/css" media="all">@import "fancy_style.css";</style> -->
<script language="JavaScript" type="text/javascript" src="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/js/styleswitcher.js"></script> 
<style type="text/css">
<!--
div.figure {float:none;width=25%;} 
div.figure p {test-aligh: center;font-style:italic;}
div.figureL {float:left;width=50%; margin:1.5em;padding:4px 4px 4px 0px;} 
div.figureL p {test-aligh: center;font-style:italic;}
div.figureR {float:right;width=50%;margin:1.5em;padding:4px 4px 4px 0px;} 
div.figureR p {test-aligh: center;font-style:italic;}

a:link {color: #0000CC; text-decoration:none}
a:visited {color: #0000CC; text-decoration:none}
a:hover {color: green; text-decoration:underline; background:#F9EDED}
a:active {color: red; text-decoration:none}

.style1 {
	color: #CC0000;
	font-weight: bold;
}
.style3 {
	color: #CC0000;
	font-weight: bold;
}
.style4 {color: #CCCCCC}
.style7 {font-family: "Courier New", Courier, mono}
.style8 {
	font-family: Arial, Helvetica, sans-serif;
	color: #810000;
}
.style9 {
	color: #3333CC;
	font-weight: bold;
}
.styleArial {
	font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;
}
.style23 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#F0F0F0;
}
.style11 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	
}

.style22 {color: #663366; font-weight: bold; }

.style10 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#F0F0F0;
}

.style24 {
	font-family: "Courier New", Courier, mono;
	color: #0000FF;
	font-size:small;
}
.style25 {
	font-family: "Courier New", Courier, mono;
	color: #0000FF;
	background-color:#FFFC9A;
	font-size:small;
}
.style15 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold; background-color:#F0F0F0; }
.style100 {
	background-color:#FFFC9A;
}



.style19 {color: #339933;
	font-weight: bold;}

.style42 {color: #0000FF; font-weight: bold; font-family: "Courier New", Courier, mono;  background-color:#F0F0F0;}
.style102 {color: #CC0000;
	font-weight: bold;
}
.style12 {color: #CC0000;
	font-weight: bold;
}
.style31 {color: #336699; font-weight: bold; }
.styleArial1 {	font-family: Arial, Helvetica, sans-serif;
	font-size:11.0pt;
}
.styleArial1 {	font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;
}
.style242 {color: #009966;
	font-weight: bold;
}

-->
</style>
</head>

<body>
<h1 align="center"><a name="lecture12" id="lecture12"></a>Lecture 12&mdash;Monday, February 6, 2012</h1>
<h2>Topics</h2>
<ul>
  <li><a href="lecture12.htm#negative">Negative binomial distribution</a>
    <ul>
      <li><a href="lecture12.htm#basic">Basic properties and characteristics</a></li>
      <li><a href="lecture12.htm#graphs">Graphs of different negative binomial distributions</a> </li>
      <li><a href="lecture12.htm#theoretical">Theoretical motivations for the negative binomial distribution</a></li>
    </ul>
  </li>
  <li><a href="lecture12.htm#generalized">Generalized linear models</a> 
    <ul>
      <li><a href="lecture12.htm#limitations">The limitations of ordinary regression models</a>      </li>
      <li><a href="lecture12.htm#defining">The defining characteristics of generalized linear models</a></li>
      <li><a href="lecture12.htm#ordinary">Ordinary regression models are generalized linear models</a></li>
      <li><a href="lecture12.htm#link">Link functions</a></li>
    </ul>
  </li>
  <li><a href="lecture12.htm#cited">Cited references</a></li>
</ul>
<h2><a name="negative" id="negative"></a>Negative binomial distribution</h2>
<p>In <a href="lecture11.htm#negative">lecture 11</a>  we gave some basic information about the negative binomial distribution and used it as the probability model for the response in a regression problem. Here we restate the basic properties of this distribution, give some examples of its flexibility, and provide some motivation for why the negative binomial distribution is particularly suitable  as a probability model for count data in ecology.</p>
<h3><a name="basic"></a>Basic properties and characteristics</h3>
<p>A negative binomial (NB) random variable is discrete. Like the Poisson distribution it is bounded below by 0 but is theoretically unbounded above. A typical use of the negative binomial distribution is as a model for count data. An example would be in describing the number of cases of Lyme disease in a North Carolina county in a year.</p>
<p name="dispersion"><a name="dispersion"></a>There are two distinct parameterizations of the negative binomial. One parameterization appears in most introductory probability texts and the second appears in most ecology texts.  In the ecological parameterization there are two parameters: &mu; and &theta;. &mu; is the mean and &theta; is the <span class="style31">dispersion parameter</span>. &theta; is also called the size (in R) or the scale parameter. &theta; is defined differently in different statistical packages. For example in SAS the dispersion parameter for the negative binomial is the reciprocal of the one reported by R.</p>
<p>The mean of the negative binomial distribution is &mu;. The variance of the negative binomial distribution is <img src="../../images/lectures/lecture12/NB&#32;quadratic.gif" alt="NB variance" width="62" height="55" align="absmiddle">. Thus  the variance is a quadratic function of the mean. Contrast this with the variance-mean relationship for the Poisson where the variance is equal to the mean. Using the  R parameterization, if we let the dispersion parameter go to infinity the  random variable that results is a Poisson random variable with parameter &mu;, i.e.,  if <img src="../../images/lectures/lecture12/NB.gif" alt="NB" width="118" height="32" align="absmiddle"> then <img src="../../images/lectures/lecture12/NB&#32;limit.gif" alt="NB limit" width="160" height="37" align="absmiddle">. The R negative binomial probability functions are <span class="style3">dnbinom</span>, <span class="style3">pnbinom</span>, <span class="style3">qnbinom</span>, <span class="style3">rnbinom</span>.</p>
<h3><a name="graphs"></a>Graphs of different negative binomial distributions</h3>
<p>To appreciate the flexibility of the negative binomial distribution and  to understand the role &theta; plays we graph a number of negative binomial distributions that have the same mean but have different values of &theta;. In the example below I fix the mean at 10 and set &theta; equal to 10, 1, and 0.1. For comparison I also show a Poisson distribution with a mean of 10. The plots are arranged in a 2 &times; 2 grid using the <span class="style22">mfrow</span> argument of <span class="style1">par</span>.</p>

<div class="style23" style="padding-left: 30px; text-indent:-30px">par(mfrow=c(2,2))</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px">  #graph NB distributions with different thetas</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  plot(0:30, dnbinom(0:30,mu=10, size=10), type='h', lwd=2, ylab='P(X=k)', xlab='k')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  legend('topright', c(expression(mu==10), expression(theta==10)), bty='n')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  plot(0:30, dnbinom(0:30,mu=10,size=1), type='h', lwd=2, ylab='P(X=k)', xlab='k')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  legend('topright', c(expression(mu==10), expression(theta==1)), bty='n')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  plot(0:30, dnbinom(0:30,mu=10,size=.1), type='h', lwd=2, ylab='P(X=k)', xlab='k')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  legend('topright', c(expression(mu==10), expression(theta==.1)), bty='n')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  plot(0:30, dpois(0:30,lambda=10), type='h', lwd=2, ylab='P(X=k)', xlab='k')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  legend('topright', c(expression(lambda==10)), bty='n')</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">  par(mfrow=c(1,1))</div><br>

<table width="600" border="0" align="center" cellpadding="5">
  <tr>
    <td><div align="center"><img src="../../images/lectures/lecture12/fig1.png" width="525" height="400" alt="fig 1"></div></td>
  </tr>
  <tr>
    <td class="styleArial1" style="padding-left: 45px; text-indent:-45px"><strong>Fig. 1</strong> &nbsp;Three negative binomial distributions with &mu; = 10 but with &theta; = 10, 1, and 0.1. A Poisson distribution with &lambda; = 10 is included for comparison.</td>
  </tr>
</table>
<p>As the plots reveal varying &theta; can have a dramatic effect on the shape of the distribution. As &theta; gets larger the negative binomial distribution more closely approaches a Poisson distribution with the same mean. One thing that is perhaps not apparent from the graphs is how much more probable  extreme values are under a negative binomial distribution. The code below calculates the probability of observing a count of 30 under the three negative binomial models in Fig. 1 and also under the Poisson distribution. Notice that for all three negative binomial distributions observing a count of 30 is at least 1000 times more likely than it is for a Poisson distribution with the same mean. </p>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #probability X=30 under negative binomial models</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px"> sapply(c(10,1,.1), function(x) dnbinom(30,mu=10,size=x))</div>
<span class="style24">[1] 0.0001927357 0.0052098685 0.0022989129</span>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> # probability X=30 for Poisson with same mean</div>
<div class="style23" style="padding-left: 30px; text-indent:-30px">dpois(30,10)</div>
<span class="style24">[1] 1.711572e-07</span>
<p>Obtaining both very large and very small counts is quite likely with a negative binomial distribution. With a Poisson distribution such a combination is essentially impossible.<br>
</p>
<h3><a name="theoretical"></a>Theoretical motivations for the negative binomial distribution</h3>

<p>Boswell and Patil (1970) list 12 distinct ways in which a negative binomial distribution can arise in practice. Of these only three appear to have much relevance to environmental science. Each is a  consequence of violating  a specific assumption of  the Poisson distribution. The assumptions of the Poisson distribution were given in <a href="lecture10.htm#assumptions">lecture 10</a> and are repeated below.</p>
<ol>
  <li><span class="style31" name="homogeneity">Homogeneity</span><span class="style31"> assumption</span>. Events occur at a constant rate &lambda; such that on average for any length of time <em>t</em> we would expect to see <em> &lambda;t </em> events. If the events are occurring over space then for an area of size <em>A</em> we would expect to see <em>&lambda;A</em> events.</li>
  <li><span class="style31">Independence assumption</span>. For any two non-overlapping intervals (or areas) the numbers of observed events are independent. </li>
  <li>If the interval is very small, then the probability of observing two or more events in that interval is essentially zero.</li>
</ol>
<p>Here are three ways the negative binomial distribution can arise from violations of a Poisson distribution.</p>
<ol>
  <li><span class="style31">Nonhomogeneous Poisson process</span>. If <em>X</em> is Poisson but &lambda; is not constant and instead varies from place to place, or from time to time, then it is said that we have a nonhomogeneous Poisson process. If we're willing to make a specific assumption about how &lambda; varies we are led directly to a negative binomial distribution. More specifically, if &lambda; has a gamma distribution (a very flexible distribution), and <em>X</em>, conditional on the value of &lambda;, has a Poisson distribution, then <em>X</em>, unconditionally, will have a negative binomial distribution. In this scenario the gamma distribution is  called a mixing distribution. 
    <p>It turns out there are two ways the conditioning can be done and they yield different mean-variance relationships. One method yields a linear mean-variance relationship, <img src="../../images/lectures/lecture12/NB1.gif" alt="NB1" width="180" height="30" align="absmiddle">, where <em>k</em> is constant. Notice that the Poisson is a special case of this with <em>k </em>= 1. This is called the <span class="style31">NB1</span> model in the econometrics literature. The second method yields the mean-variance relationship given above, <img src="../../images/lectures/lecture12/NB2.gif" alt="NB2" width="212" height="55" align="absmiddle">. This is sometimes called the <span class="style31">NB2</span> model.</p>
</li>
  <li> Independence. If we relax the independence assumption of the Poisson model in a special way so that the occurrence of one event makes the occurrence of the next event more likely, we get a negative binomial distribution. The special way to relax independence is called a <span class="style31">Polya-Eggenberger urn model</span>. This is one of the many so-called Polya urn models that exist in the literature. The description of this urn model is as follows. 
    <ul>
      <li>Suppose we have an urn with <em>N</em> balls in it of which a fraction <em>p</em> are red and the remaining fraction 1 &ndash; <em>p</em> are black. </li>
      <li>At each trial we draw one ball from the urn, observe its color, and return it to the urn along with <em>&theta; &times; N</em> balls of the same color (where usually we take 0 &lt; &theta; &lt; 1 although this is not required). By adding more balls of the same color we make the occurrence of the same event at the next trial more likely.</li>
      <li>Let <em>X<sub>r</sub></em>= number of red balls in the urn after <em>r</em> trials of this sort. It is not hard to write down the formula for <img src="../../images/lectures/lecture12/probxrequalsk.gif" alt="Prob Xr equals K" width="87" height="32" align="absmiddle"> but it is rather involved, particularly the simplification that is required to proceed further, so we'll skip it.</li>
      <li>It can be shown that if we take the limit of this expression in a certain way, i.e., <img src="../../images/lectures/lecture12/rgoestoinfinity.gif" alt="r goes to infinity" width="57" height="17" align="absmiddle"> while <img src="../../images/lectures/lecture12/pandtheta.gif" alt="p and theta" width="78" height="27" align="absmiddle">, then the limiting distribution is negative binomial.</li>
    </ul>
    <p>It's hard to know how useful this result is in practice. What is important is that the Polya-Eggenberger scheme clearly violates the independent increments hypothesis that was one of the three basic assumptions of the Poisson model. Thus we see that if either one of the major assumptions of the Poisson model, homogeneity or independence, is violated we can be led, under certain circumstances, to a negative binomial model. </p>
  </li>
</ol>

<ol start=3>
  <li><span class="style31">Generalized Poisson</span> model. Suppose that  events are actually clustered and that the clusters have a Poisson distribution. Suppose within each cluster the number of observed events follows a <a href="http://en.wikipedia.org/wiki/Logarithmic_distribution">logarithmic distribution</a> (also called a log series distribution). This is a particular long-tailed distribution that has been used to model species abundances (<a href="http://www.biolbull.org/cgi/reprint/198/1/152.pdf">Dewdney 2000</a>). Now suppose we lay down a grid, not realizing that there are  clusters present, and just count up the events we see in the cells of our grid. The  distribution of the counts that results is negative binomial. </li>
</ol>
<p>It is easy to imagine each of these three mechanisms occurring in practice.
</p>
<ul>
  <li>Suppose seeds are randomly distributed in an environment (governed by a Poisson model) and that each seed germinates and gives rise to a number of stems via vegetative reproduction, the number of stems governed largely by how long the plant has been present in the environment. The generalized Poisson model suggests that this might yield a negative binomial distribution for the number of plants present. </li>
  <li>Suppose the seeds of a plant species  are heterogeneous in their propensity to germinate. This would imply a nonconstant &lambda; in a Poisson model yielding a nonhomogeneous Poisson process. This may lead to a negative binomial distribution of counts of the number of adults we see in a habitat.</li>
  <li>In the case of a contagious disease where initial inoculates are distributed randomly according to a Poisson process, the Polya-Eggenberger urn model suggests we might end up with a distribution that is negative binomial.</li>
</ul>
<p name="zeroinflation"><a name="zeroinflation"></a>A further application of the negative binomial distribution is with zero-inflated count data  (meaning that we see more zeros than a fitted Poisson model can predict). The negative binomial distribution can often be successfully fit to zero-inflated data. </p>
<p name="zeroinflation">The negative binomial distribution is useful as a model for count data whenever we suspect  heterogeneous rates of occurrence, lack of independence,  clustering, or zero inflation. </p>
<h2><a name="generalized"></a>Generalized linear models</h2>
<p>Generalized linear models are regression models that include the normal regression model as a special case. They extend linear regression to  probability distributions that are members of the exponential family of distributions. These include the normal, Poisson, binomial, and gamma distributions, among others. The negative binomial distribution is technically not a member of this group but it is possible to extend the methodology to include it. Generalized linear models were developed to fix the various problems we've already encountered with normal regression models.</p>
<h3><b><a name="limitations" id="limitations"></a>The  limitations of ordinary regression models</b></h3>
<ol>
  <li>Response variables of interest in ecology are often not normally distributed nor do they tend to exhibit constant variance. While transformations can sometimes &quot;fix&quot; one or both of these problems, transformations introduce their own baggage and make the resulting model difficult to interpret. There's also no guarantee that a suitable transformation will be found. </li>
  <li>Response variables may have a restricted range. For instance count data are required to be non-negative and proportions are required to lie between zero and one. The normal distribution does not have such a range restriction and hence may not be an appropriate probability model for such data.</li>
  <li>It is often observed in ecological data that the variance is a function of the mean. This is especially true of restricted range data when values are near the boundary of their natural range. Limited range data near a boundary will necessarily exhibit a skewed distribution because of truncation at the boundary. This in turn limits the amount of variability they can display, at least in one direction. </li>
  <li>The use of an identity link can cause problems. Because  predictors do not have the same range restrictions as does the response variable, the systematic component can yield predicted values of the mean outside the legal range of the data.</li>
</ol>
<h3><a name="defining" id="defining"></a>The defining characteristics of generalized linear models</h3>
<p>Generalized linear models (GLIMs) were designed to overcome the limitations described above. Proposed in the 1970s by McCullagh and Nelder (McCullagh and Nelder, 1989), GLIMs serve to unify a  number of disparate modeling protocols under a single umbrella. While some revisionist statisticians think the significance of the GLIM paradigm is overstated (Lindsey 2004), I think it is fair to say that  generalized linear models did for statistical modeling what plate tectonics did for geology. GLIMs provided a unifying vision to statistical modeling and brought a degree of order to what was otherwise a set of rather chaotic and seemingly arbitrary collection of procedures.</p>
<p>Formally a  generalized linear model consists of the following three components. </p>
<ol>
  <li><span class="style31" name="random">Random component</span>. The response variables <em>Y</em><sub>1</sub>, <em>Y</em><sub>2</sub>, &hellip; , <em>Y<sub>n</sub></em> are assumed to be independent and drawn from a member of the exponential family of distributions. The exponential family includes many of the standard probability distributions including the Poisson, normal,  binomial, gamma, and inverse Gaussian distributions. (The negative binomial can be forced into the exponential family if the overdispersion parameter is treated as a constant.) Thus the normality and constant variance assumptions are relaxed for GLIMs. </li>
  <li><span class="style31" name="systematic">Systematic component</span>. The <em>p</em> covariates are combined to form a linear predictor. The linear predictor is typically denoted by the Greek letter &eta; (eta). <img src="../../images/lectures/lecture12/eta.gif" width="256" height="30" align="absmiddle">. This assumption is identical for both ordinary regression models and GLIMs. </li>
  <li><span class="style31" name="link">Link function</span><span name="link">.</span> The systematic component and random component are linked together via a link function <em>g</em>. For GLIMs the link function<em> g</em> can be selected from a large class of functions, although there are certain natural choices called canonical links. The only restriction on <em>g</em> is that it be differentiable and monotonic. Thus for a GLIM we write the regression model as follows.</li>
</ol>

  <p align="center"><img src="../../images/lectures/lecture12/GLIM&#32;link.gif" width="288" height="32" alt="glm link"></p>

<p>Because we require <em>g</em> to be monotonic, it follows that <em>g</em> is invertible. Thus we can also write this last expression in terms of the inverse link function, <img src="../../images/lectures/lecture12/ginverse.gif" width="30" height="30" align="absmiddle">.</p>

    <p align="center"><img src="../../images/lectures/lecture12/GLIM&#32;inverse&#32;link.gif" width="303" height="37" alt="inverse link"></p>

<p>Written this way we can see that GLIMs have the potential of solving the range restriction problem described above. Because the linear predictor is connected to the mean through <img src="../../images/lectures/lecture12/ginverse.gif" width="30" height="30" align="absmiddle">, a judicious choice of link function can constrain the predictions to map onto a desired range. The so-called canonical link functions for the normal, Poisson, binomial, and gamma distributions are respectively the identity, log, logit, and reciprocal links. In most software packages a log link is used for the negative binomial distribution.</p>
<h3><a name="ordinary" id="ordinary"></a>Ordinary regression models are generalized linear models</h3>
<p>To see that normal regression models are also generalized linear models, we identify the random component, the systematic component, and the link function.</p>
<ol>
  <li><span class="style31">Random component</span>: The response variables <em>Y</em><sub>1</sub>, <em>Y</em><sub>2</sub>, &hellip; , <em>Y<sub>n</sub></em> are assumed to be independent and normally distributed. More formally we assume <img src="../../images/lectures/lecture12/GLM&#32;random.gif" alt="random" width="267" height="35" align="absmiddle">. Observe that the mean is allowed to vary for each <em>Y<sub>i</sub></em> but that the variance does not. </li>
  <li><span class="style31">Systematic component</span>: The <em>p</em> covariates are combined to form a linear predictor. The linear predictor is represented by the Greek letter &eta; (eta). <img src="../../images/lectures/lecture12/eta.gif" alt="eta" width="267" height="30" align="absmiddle"></li>
  <li><span class="style31">Link function</span>: The systematic component and random component are linked together via a link function <em>g</em>(&mu;) = &eta;. For ordinary regression models the function<em> g</em> is taken to be the identity link, <em>g</em>(&mu;) = &mu;, so that we assume &mu; = &eta; . Using <em>E</em> to denote  expectation, the operation of taking the mean, we can write this assumption as follows. </li>
</ol>
<p align="center"><img src="../../images/lectures/lecture12/GLM&#32;link.gif" width="325" height="32" alt="GLM link"></p>
<h3><a name="link"></a>Link functions</h3>
<p>Table 1  lists the  probability distributions typically used as the random component in generalized linear models along with their canonical and usual link functions. When a probability distribution is written in its exponential form  the mean parameter can appear as part of a functional expression. This function of &mu; is referred to as the canonical link. Historically, it was useful to use the canonical link as the link function because it made things simpler. This is no longer necessary and a number of other link functions are available in R. For instance, although the reciprocal function is  the canonical link for the gamma distribution, the log link is more commonly used because it guarantees that the mean as a function of  the linear predictor will be positive. The canonical link function for the negative binomial distribution is rarely used because it is difficult to interpret.</p>
<table width="420" border="0" align="center" cellpadding="1" cellspacing="1">
  <tr>
    <td class="styleArial1" style="padding-left: 55px; text-indent:-55px"><strong>Table 1</strong>&nbsp; Canonical links for members of the exponential family</td>
  </tr>
</table>
<table width="650" border="1" align="center" cellpadding="5" cellspacing="1">
  <tr  bgcolor="#F1D2D8">
    <th scope="col">Probability Distribution </th>
    <th scope="col">Canonical Link g(&mu;)</th>
    <th scope="col">Usual link</th>
    <th scope="col">Links available in R</th>
  </tr>
  <tr>
    <td><div align="center">Poisson</div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;poisson.gif" width="47" height="27" alt="poisson link"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;poisson.gif" width="47" height="27" alt="poisson link"></div></td>
    <td>log, identity,  sqrt</td>
  </tr>
  <tr>
    <td><div align="center">Normal</div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;normal.gif" width="18" height="21"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;normal.gif" width="18" height="21"></div></td>
    <td>identity, log,  inverse</td>
  </tr>
  <tr>
    <td><div align="center">Binomial</div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;binomial.gif" width="97" height="62" alt="binomial link"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;binomial.gif" width="97" height="62" alt="binomial link"></div></td>
    <td>logit, probit, cauchit, log, cloglog (complementary log-log) </td>
  </tr>
  <tr>
    <td><div align="center">Gamma</div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;gamma.gif" width="22" height="55" alt="gamma link"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;poisson.gif" width="47" height="27" alt="poisson link"></div></td>
    <td>inverse, identity,  log</td>
  </tr>
  <tr>
    <td><div align="center">Inverse Gaussian </div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;ig.gif" width="30" height="55"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;ig.gif" width="30" height="55"></div></td>
    <td>1/mu^2, inverse, identity,  log</td>
  </tr>
  <tr>
    <td><div align="center">Negative binomial</div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;NB.gif" width="100" height="60" alt="NB link"></div></td>
    <td><div align="center"><img src="../../images/lectures/lecture12/link&#32;poisson.gif" width="47" height="27" alt="poisson link"></div></td>
    <td>log, sqrt,  identity</td>
  </tr>
</table>
<h2><b><a name="cited"></a>Cited references</b></h2>
<ul>

  <li> Boswell, M. T. and G. P. Patil. 1970. Chance mechanisms generating the negative binomial distributions. In G. P. Patil (editor), <em>Volume 1: Random Counts in Models and Structures</em>, Pennsylvania State University Press, University Park, PA, 1&ndash;22.</li>
  <li>Dewdney, A. K. 2000. A dynamical model of communities and a new species-abundance distribution. <em>Biological Bulletin</em> <strong>198</strong>: 152&ndash;165.</li>
  <li> Lindsey, J. K. 2004. <em>Introduction to Applied Statistics: A Modeling Approach</em>. Oxford University Press: Oxford. </li>
  <li>McCullagh, P. and J. A. Nelder. 1989. <em>Generalized Linear Models, 2nd edition</em>. Chapman &amp; Hall: London.</li>
</ul>
<p align="center"><a href="../../index.html">Course Home Page</a> </p>
<hr align="center" width="75%">
<!--Standard footer follows -->
<p></p>
<table width="650" border="3" cellspacing="2" cellpadding="2" align=
"CENTER">
  <tr bgcolor="#CCCCCC">
    <td width="100%"><font size=-1>Jack Weiss<br>
          <i>Phone: </i>(919) 962-5930<br>
          <i>E-Mail:</i> jack_weiss@unc.edu<br>
          <i>Address: </i>Curriculum for the Environment and Ecology, Box 3275, University of North Carolina, Chapel Hill, 27599<br>
      Copyright &copy; 2012<br>
      Last Revised--February 13, 2012<br>
      URL: <a href="lecture12.htm#lecture12" target="_self">https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/lecture12.htm</a></font></td>
  </tr>
</table>
<p align="center">&nbsp;</p>
</body>
</html>
