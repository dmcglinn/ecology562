<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Lecture 37&mdash;Friday, April 13, 2012</title>

<style type="text/css">
<!--
a:link {color: #0000CC; text-decoration:none}
a:visited {color: #0000CC; text-decoration:none}
a:hover {color: green; text-decoration:underline; background:#F9EDED}
a:active {color: red; text-decoration:none}
div.figure {float:none;width=25%;}
div.figure p {test-align: center;font-style:italic;}
div.figureL {float:left;width=50%; margin:1.5em;padding:4px 4px 4px 0px;}
div.figureL p {test-align: center;font-style:italic;}
div.figureR {float:right;width=50%;margin:1.5em;padding:3px 4px 4px 0px;}
div.figureR p {test-align: center;font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;}

.subtd {margin-left: 2em;}

.subtd2 {margin-left: 2em;
   margin-right: 2em;}
.eq { width: 100%; }
.eq th { text-align: right;
         vertical-align: absolute middle;
		 font-weight: normal; }
		 
.style4 {	color: #CC0000;
	font-weight: bold;
}
.style11 {font-family: "Courier New", Courier, mono;}
.style22 {color: #663366; font-weight: bold; }
.style10 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#F0F0F0;
}
.style33 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#FFFACD;
}

.style34 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold; background-color:#FFFACD; }
.style43 {color: #0000FF; font-weight: bold; font-family: "Courier New", Courier, mono;  background-color:#FFFACD;}



.style25 {
	font-family: "Courier New", Courier, mono;
	color: #003399;
	font-size:small;
	background-color:#FFFC9A;
}

.style35 {color: #339933; font-weight: bold; font-family: "Courier New", Courier, mono; }
.style15 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold; background-color:#F0F0F0; }

.style16 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold;background-color:#C5E9EB; }
.style17 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold; }

.style19 {color: #339933;
	font-weight: bold;}
.style40 {color: #0000FF; font-weight: bold; font-family: "Courier New", Courier, mono;}
.style42 {color: #0000FF; font-weight: bold; font-family: "Courier New", Courier, mono;  background-color:#F0F0F0;}

.style1 {font-family: "Courier New", Courier, mono;}

.sasnavy {font-size:11.0pt;font-family:"Courier New"; font-weight: bold;
color:navy;background:white; }

.sasblack {font-size:11.0pt;font-family:"Courier New";
color:black;background:white; }

.sasblue {font-size:11.0pt;font-family:"Courier New";
color:blue;background:white; }

.saspurple {font-size:11.0pt;font-family:"Courier New";
color:purple;background:white; }

.sasteal {font-size:11.0pt;font-family:"Courier New";
color:teal;background:white; }

.sasgreen {font-size:11.0pt;font-family:"Courier New";
color:green;background:white; }

.sasblack9 {font-size:9.0pt;font-family:"Courier New";
color:black;background:white; }

.sasblue9 {font-size:9.0pt;font-family:"Courier New";
color:blue;background:white; }
.style41 {	color: #00C;
	font-weight: bold;
}

.style61 {	color: #000000;
	font-weight: bold;
}

.styleArial {
	font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;
}
.styleArial2 {
	font-family: Arial, Helvetica, sans-serif;
}
.style66 {
	font-family: Arial, Helvetica, sans-serif;
}
.stylecayenne {
	color: #800000;
}
.style44 {font-family: "Courier New", Courier, mono}
.style9 {	color: #339900;
	font-weight: bold;
}
.style101 {font-family: "Courier New", Courier, mono}


.style24 {
	font-family: "Courier New", Courier, mono;
	color: #0000FF;
	font-size:small;
}




.style8 {
	font-family: Arial, Helvetica, sans-serif;
	color: #810000;
}

.style14 {color: #0000FF; font-size: smaller; font-family: "Courier New", Courier, mono; }
.style14 {color: blue;
	font-family: "Courier New", Courier, mono;}
.style151 {font-family: "Courier New", Courier, mono; color: #009900; }
.style31 {color: #336699; font-weight: bold; }
.style32 {color: #333333;
	font-weight: bold;
}
.style3 {	color: #CC0000;
	font-weight: bold;
}
.style36 {color: #CC0033; font-weight: bold; }
.style102 {font-size: smaller}
.style6 {	color: #0033CC;
	font-size: smaller;
}
.style7 {	color: #CC0000;
	font-weight: bold;
}
div.figureR1 {float:right;width=50%;margin:1.5em;padding:4px 4px 4px 0px;}
.style103 {color: #0033CC; font-size: smaller; font-family: "Courier New", Courier, mono; }
.style1021 {color: #CC0000;
	font-weight: bold;
}
.style361 {color: #660099;
	font-weight: bold;
}
.style104 {color: #CC0000;
	font-weight: bold;
}
.style23 {	font-family: "Courier New", Courier, mono;
	color: #000000;
}
.style241 {	font-family: "Courier New", Courier, mono;
	color: #003399;
	font-size:small;
}
.style331 {color: blue; font-family: "Courier New", Courier, mono; font-size: smaller; }
.style37 {	color: #FF0000;
	font-weight: bold;
}
.style431 {color: #339933; font-weight: bold; font-family: "Courier New", Courier, mono; }
.style22 {	color: #990099;
	font-weight: bold;
}
.style2 {	color: #CC0000;
	font-size:large;
}
.style221 {color: #663366; font-weight: bold; }
-->
</style>
</head>

<body>
<h1 align="center"><a name="lecture37" id="lecture37"></a>Lecture 37 (lab 12)&mdash;Friday, April 13, 2012</h1>
<h2>Topics</h2>
<ul>
  <li><a href="lecture37.htm#overview">Overview of the data</a></li>
  <li><a href="lecture37.htm#density">Density as a response variable</a></li>
  <li><a href="lecture37.htm#regression">Regression trees</a></li>
  <li><a href="lecture37.htm#classification">Classification trees</a></li>
  <li><a href="lecture37.htm#forest">Random forests</a></li>
</ul>
<h2>R functions and commands demonstrated</h2>
<ul>
  <li><a href="lecture37.htm#partykit">as.party</a> (from the <span class="style19">partykit</span> package) converts an <span class="style3">rpart</span> object to a <span class="style3">party</span> object.</li>
  <li><a href="lecture37.htm#dotchart">dotchart</a> produces a dot chart of a variable.</li>
  <li><a href="lecture37.htm#mosaic">mosaicplot</a> produces a mosaic plot, a graphical representation of a contingency table of cross-classified data.</li>
  <li><a href="lecture37.htm#plot">plot</a> when applied to an <span class="style4">rpart</span> object generates a binary tree representation of the results.</li>
  <li><a href="lecture37.htm#plotcp">plotcp</a> (from the <span class="style19">rpart</span> package) plots the cross-validation error (<span class="style1">xerror</span>) versus the cost complexity parameter (<em>c<sub>p</sub></em>) for trees of various sizes. It also displays the one standard deviation upper limit calculated from the model with the smallest cross-validation error.</li>
  <li><a href="lecture37.htm#printcp">printcp</a> (from the <span class="style19">rpart</span> package) prints the <em>c<sub>p</sub></em> table for a sequence of best trees.</li>
  <li><a href="lecture37.htm#prune">prune</a> (from the <span class="style19">rpart</span> package) is used to prune an existing tree based on values of the cost complexity parameter <em>c<sub>p</sub></em>. </li>
  <li><a href="lecture37.htm#forest">randomForest</a> (from the <span class="style19">randomForest</span> package) is used to fit random forests.</li>
  <li><a href="lecture37.htm#rpart">rpart</a> (from the <span class="style19">rpart</span> package) is used to carry out binary recursive partitioning resulting in either a regression or classification tree.</li>
  <li><a href="lecture37.htm#rpartc">rpart.control </a>(from the <span class="style19">rpart</span> package) is used in the <span class="style221">control</span> argument of <span class="style3">rpart</span> to set control parameters that affect the <span class="style4">rpart</span> algorithm and change the manner in which the tree is constructed.</li>
  <li><a href="lecture37.htm#text">text</a> when applied to an <span class="style4">rpart</span> object adds text to an already existing graph of a regression or classification tree.</li>
</ul>
<h2>R function options</h2>
<ul>
  <li><a href="lecture37.htm#branch">branch=</a> argument to <span class="style4">plot</span> when plotting an <span class="style4">rpart</span> object. It determines the shape of the branches displayed in the tree. Values can range from<span class="style221"> branch = 0</span> which produces trees with shouldered, rectangular branches to <span class="style221">branch=1</span> for trees with V-shaped branches. Intermediate values yield intermediate branching patterns.</li>
  <li><a href="lecture37.htm#control">control</a>= argument to <span class="style4">rpart</span> to set control parameters that affect the manner in which the tree is constructed.</li>
  <li><a href="lecture37.htm#cp">cp=</a> argument to <span class="style4">prune</span> and <span class="style4">rpart.control</span> for selecting a value of the cost complexity parameter to control the maximum size of the tree.</li>
  <li><a href="lecture37.htm#importance">importance=</a> argument to <span class="style3">randomForest</span> specifies whether importance statistics should be calculated for each variable.</li>
  <li><a href="lecture37.htm#margin">margin</a>= argument to <span class="style4">plot</span> when plotting an <span class="style4">rpart</span> object. It is used to expand the amount of white space around the tree to prevent truncation of any text that is added later with the <span class="style4">text</span> function.</li>
  <li><a href="lecture37.htm#method">method=</a> argument to <span class="style4">rpart</span> specifies whether a regression tree, <span class="style221">method='anova'</span>, or a classification tree, <span class="style221">method='class'</span>, is desired. By default <span class="style4">rpart</span> uses the class of the response variable to make this determination.</li>
  <li><a href="lecture37.htm#minsplit">minsplit</a>= argument to <span class="style4">rpart.control</span> for setting the minimum number of observations that must exist at a node in order for a split to be attempted.</li>
  <li><a href="lecture37.htm#parms">parms</a>= argument to <span class="style4">rpart</span> to set tree parameters, for instance, the kind of impurity measure to use in building a classification tree.</li>
  <li><a href="lecture37.htm#pretty">pretty=</a> argument to <span class="style3">text</span> controls  how the categories of factor variables are displayed on a plotted tree.</li>
  <li><a href="lecture37.htm#parms">split=</a> is for setting the split criterion in classification trees. It is entered as an argument of the <span class="style221">parms</span> parameter of <span class="style4">rpart</span>.</li>
  <li><a href="lecture37.htm#partykit">tp_args=</a> (from the <span class="style19">partykit</span> package) is used to pass arguments to the <span class="style3">plot</span> function to control  the graphical display of the terminal nodes when plotting <span class="style3">party</span> objects.</li>
  <li><a href="lecture37.htm#uniform">uniform=</a> argument to <span class="style4">plot</span> when plotting an <span class="style4">rpart</span> object. Setting <span class="style221">uniform=T</span> results in equal length branches rather than branch lengths that measure the relative decrease in impurity (the default).</li>
  <li><a href="lecture37.htm#usen">use.n</a>= argument to <span class="style4">text</span> for adding text to an <span class="style4">rpart</span> object. Setting <span class="style221">use.n=T</span> causes the sample sizes at terminal nodes to be added to regression trees and the actual numbers of observations in the individual categories at each leaf to be added to classification trees.</li>
</ul>
<h2>R packages used </h2>
<ul>
  <li><a href="lecture37.htm#rpart">rpart</a> for the various functions needed to fit and display classification and regression trees.</li>
  <li><a href="lecture37.htm#partykit">partykit</a> for enhanced graphics.</li>
  <li><a href="lecture37.htm#forest">randomForest</a> for random forests.</li>
</ul>
<h2><a name="overview"></a>Overview of the  data</h2>
<p>The data are from <a href="lecture37.htm#zuur">Zuur et al. (2007)</a> who use it to introduce classification and regression trees in their Chapter 9. The data set used to illustrate regression trees is a Bahamas fisheries data set consisting of unpublished data from The Bahamas National Trust / Greenforce Andros Island Marine Study. <a href="lecture37.htm#zuur">Zuur et al. (2007)</a> describe the data as follows (p. 147): </p>
<blockquote>
  <p class="styleArial">Parrotfish densities are used as the response variable, with the explanatory variables: algae and coral cover, location, time (month), and fish survey method (method 1: point counts, method 2: transects). There were 402 observations measured at 10 sites.</p>
</blockquote>
<p>They choose not to use <span class="style8">CoralRichness</span> in the analysis and we will follow suit.
  
  Because the response variable <span class="style8">Parrot</span> is parrotfish density, a continuous variable,  we will use these data to construct a regression tree.
<div class="style10" style="padding-left: 30px; text-indent:-30px"> Bahama &lt;- read.table( 'ecol 562/Bahama.txt', header=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> names(Bahama)</div>
<span class="style24"> [1] &quot;Sample&quot;        &quot;Parrot&quot;        &quot;CoralRichness&quot; &quot;CoralTotal&quot;    &quot;Month&quot;         &quot;Station&quot; <br>
[7] &quot;Method&quot; </span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> dim(Bahama)</div>
<span class="style24"> [1] 402   7</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> Bahama[1:4,]</div>
<span class="style24">&nbsp;&nbsp;Sample Parrot CoralRichness CoralTotal Month Station Method<br>
1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1  &nbsp;25.46            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.73     &nbsp;&nbsp;&nbsp;&nbsp;5       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1<br>
2      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2  &nbsp;16.55            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.73     &nbsp;&nbsp;&nbsp;&nbsp;5       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1<br>
3      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3  &nbsp;15.28            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.73     &nbsp;&nbsp;&nbsp;&nbsp;5       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1<br>
4      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4  &nbsp;10.19            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.73     &nbsp;&nbsp;&nbsp;&nbsp;5       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span>
<p><a href="lecture37.htm#zuur">Zuur et al. (2007)</a> use a  second data set to illustrate classification trees. They describe the data and their objectives as follows (p. 152&ndash;153). </p>
<blockquote>
  <p class="styleArial">These data are from an annual ditch monitoring programme at a waste management and soil recycling facility in the UK. The soil recycling facility has been storing and blending soils on this site for over many years, but it has become more intensive during the last 8 to 10. Soils are bought into the stockpile area from a range of different sites locations, for example from derelict building sites, and are often saturated when they arrive. They are transferred from the stockpile area to nearby fields and spread out in layers approximately 300 mm deep. As the soils dry, stones are removed, and they are fertilised with farm manure and seeded with agricultural grasses. These processes recreate the original soil structure, and after about 18 months, the soil is stripped and stockpiled before being taken off-site to be sold as topsoil.</p>
  <p class="styleArial">The main objective of the monitoring was to maintain a long-term surveillance of the surrounding ditch water quality and identify any changes in water quality that may be associated with the works and require remedial action. The ecological interest of the site relates mainly to the ditches: in particular the large diversity of aquatic invertebrates and plants, several of which are either nationally rare or scarce. Water quality data were collected four times a year in Spring, Summer, Autumn and Winter, and was analysed for the following parameters: pH, electrical conductivity (&mu;S/cm), biochemical oxygen demand (mgl<sup>&ndash;1</sup>), ammoniacal nitrogen (mgl<sup>&ndash;1</sup>), total oxidised nitrogen, nitrate, nitrite (mgl<sup>&ndash;1</sup>), total suspended solids (mgl<sup>&ndash;1</sup>), chloride (mgl<sup>&ndash;1</sup>), sulphate (mgl<sup>&ndash;1</sup>), total calcium (mgl<sup>&ndash;1</sup>), total zinc (&mu;gl<sup>&ndash;1</sup>), total cadmium (&mu;gl<sup>&ndash;1</sup>), dissolved lead (&mu;gl<sup>&ndash;1</sup>), dissolved nickel (&mu;gl<sup>&ndash;1</sup>), orthophosphate (mgl1) and total petroleum hydrocarbons (&mu;gl<sup>&ndash;1</sup>). In addition to water quality observations, ditch depth was measured during every visit. The data analysed here was collected from five sampling stations between 1997 and 2001. Vegetation and invertebrate data were also collected, but not used in this example.</p>
  <p class="styleArial">The underlying question now is whether we can make a distinction between observations from different ditches based on the measured variables.</p>
</blockquote>
<p>The response variable, <span class="style8">Site</span>, is a categorical variable with five categories and hence will be used to construct a classification tree.
<div class="style10" style="padding-left: 30px; text-indent:-30px">Ditch &lt;- read.table('ecol 562/Ditch.txt', header=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">names(Ditch)</div>
<span class="style24">&nbsp;[1] &quot;Site&quot;                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Year&quot;                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Month&quot;                   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Depth&quot; <br>
&nbsp;[5] &quot;pH&quot;                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Conductivity&quot;            &nbsp;&nbsp;&nbsp;&nbsp;&quot;BOD&quot;                     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Ammoniacal_Nitrogen&quot; <br>
&nbsp;[9] &quot;Total_Oxidised_Nitrogen&quot; &quot;Suspended_Solids&quot;        &quot;Chloride&quot;                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Sulphate&quot; <br>
[13] &quot;Total_Calcium&quot;           &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Total_Zinc&quot;              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Total_Cadmium&quot;           &quot;Total_Lead&quot; <br>
[17] &quot;Total_Nickel&quot;            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Total_Phosphate&quot; </span>
<div class="style10" style="padding-left: 30px; text-indent:-30px">dim(Ditch)</div>
<span class="style24">[1] 48 18</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px">Ditch[1:4,]</div>
<span class="style24">&nbsp; Site Year Month Depth&nbsp;&nbsp; pH Conductivity BOD Ammoniacal_Nitrogen Total_Oxidised_Nitrogen<br>
1&nbsp;&nbsp;&nbsp; 1 1997&nbsp;&nbsp;&nbsp; 11&nbsp;&nbsp;&nbsp; NA 7.62&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 511 7.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.42<br>
2&nbsp;&nbsp;&nbsp; 1 1999&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp; 0.40 8.51&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 778 7.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.43<br>
3 &nbsp;&nbsp;&nbsp;1 1999&nbsp;&nbsp;&nbsp;&nbsp; 4&nbsp; 0.25 7.71&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 517 3.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.88<br>
4&nbsp;&nbsp;&nbsp; 1 1999&nbsp;&nbsp;&nbsp;&nbsp; 7&nbsp; 0.40 7.77&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1892 3.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.05<br>
&nbsp; Suspended_Solids Chloride Sulphate Total_Calcium Total_Zinc Total_Cadmium Total_Lead<br>
1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 441&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 43&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 63&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 104.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.18&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NA&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.07<br>
2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 759&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 78&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 196&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 141.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.24&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.005&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.14<br>
3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 65&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 123&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 77.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.04&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.005&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.05<br>
4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 51&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 266&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 405&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 158.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.05&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.005&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.05<br>
&nbsp; Total_Nickel Total_Phosphate<br>
1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NA<br>
2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.05<br>
3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.30<br>
4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.17</span>
<p>The <span class="style8">Ditch</span> data set contains only 48 observations. This makes it less than ideal for building a tree model. </p>
<h2><a name="density"></a>Density as a response variable</h2>
<p>It's worth considering how we might analyze the Bahama data using a parametric regression model. Regression trees are indifferent to nature of the response variable but this does matter when choosing a probability distribution for a parametric model. The variable of interest,  parrotfish density, presumably was obtained by counting parrotfish   and dividing the total by the area surveyed. While this may seem like a perfectly natural variable, ratios can be exceedingly difficult to analyze  statistically. We can get a sense of the difficulty when we look at the distribution of the parrotfish density variable (Fig. 1).</p>
<table width="525" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig0.png" width="495" height="295" alt="density distribution"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 1&nbsp;</strong>&nbsp;Distribution of parrotfish densities</td>
  </tr>
</table>
<p>Fig. 1 is a bar chart of the different parrotfish densities in the data set.  Keep in mind that the overall distribution of the response is largely irrelevant in regression. Instead it is the distribution of the response at various predictor combinations that matters. Because density is a non-negative quantity and we see from the graph that much of the data is  close to and even achieves its lower boundary of zero, a distribution that permits negative values such as a normal distribution is not likely to be a good choice here. If we turn to positive distributions such as the lognormal and gamma we find there is another problem. These distributions don't allow zero values. </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">library(MASS)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">fitdistr(Bahama$Parrot, 'lognormal')</div>
<span class="style24">  Error in fitdistr(Bahama$Parrot, &quot;lognormal&quot;) : <br>
&nbsp; need positive values to fit a log-Normal</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> glm(Bahama$Parrot~1, data=Bahama, family=Gamma)</div>
<span class="style24">  Error in eval(expr, envir, enclos) : <br>
&nbsp; non-positive values not allowed for the gamma family</span>
<p>Yet 7% (<em>n</em> = 29) of the observed parrotfish densities are zero. One solution is to assume the zeros aren't really zero, but are  small positive numbers that fall below our detection threshold. Alternatively  we could  analyze the zeros separately by fitting a binomial model to the presence-absence of parrotfish. Then conditional on parrotfish being present we could fit a lognormal model to the nonzero densities. Splitting up the data like this diminishes our ability to detect effects of interest. It is quite likely that the factors that  cause density to be low  also  cause density to be zero.</p>
<p>All of these issues have arisen because we've chosen to record the response variable as density.  The actual variable in nature is a count, the number of parrotfish observed on a transect, which we then chose to divide by the area surveyed.  If the transects vary in length then the number of fish observed will vary also, so we need to control for area. Rather than forming a ratio we can control for the effect of area by including it in the regression model as a covariate.</p>
<div class="style1" style="padding-left: 30px; text-indent:-30px">parrotfish.count ~ b0 + b1*area + b2*x</div>
<p>The advantage of doing it this way is that  the response variable is still a count and we can make use of probability models for counts (Poisson, negative binomial, etc.)  all of which permit a count to be equal to zero.</p>
<p>If we insist that the results be interpretable as effects on  density then there is yet another option: use parrotfish counts as the response variable but use log(area) as an offset rather than as a predictor. An offset is a term in a regression model whose coefficient is constrained to be 1. In R we would fit a model with an offset as follows.</p>
<div class="style1" style="padding-left: 30px; text-indent:-30px">glm(parrotfish.count ~ offset(log(area)) + x, family=poisson)</div>
<p>Because the default link function for Poisson regression is a log link, the above syntax fits the following regression model.</p>
<p align="center"><img src="../../images/lectures/lecture37/loglink.gif" width="360" height="117" alt="offset"></p>
<p>where the last step follows from a property of logarithms. So if we assume parrotfish counts  have a Poisson distribution (which allows zeros), then by including log area as an offset we end up with a model for density. The same result holds if the parrotfish counts are assumed to have a negative binomial distribution. The bottom line is that fitting models to densities is a messy statistical problem, while fitting models to counts is easy. Avoid working with densities unless you have no other choice.</p>

<h2><a name="regression"></a>Regression trees</h2>
<p><a name="rpart"></a><a name="method"></a>Regression trees are fit with the <span class="style4">rpart</span> function in the the <span class="style19">rpart</span> package. The default syntax is identical to that which we've used with most of the regression functions of R. Because <span class="style8">Month</span>,  <span class="style8">Station</span>, and <span class="style8">Method</span> are recorded with numerical values I declare them as factors explicitly in the model formula. Because <span class="style8">Parrot</span> is a continuous variable, <span class="style221">rpart</span> fits a regression tree. To explicitly request a regression tree we can add the argument <span class="style221">method=&quot;anova&quot;</span>.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">library(rpart)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">parrot_tree &lt;- rpart(Parrot ~ CoralTotal + factor(Month) + factor(Station) + factor(Method), data = Bahama)</div>
<p>The default print method for <span class="style4">rpart</span> is to print a text representation of the tree. Generally you shouldn't use the <span class="style4">summary</span> function on an <span class="style4">rpart</span> object unless you want to see all the details of the tree construction.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">parrot_tree</div>
<span class="style24">n= 402 </span>
<p><span class="style24">node), split, n, deviance, yval<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* denotes terminal node</span>
<p><span class="style24"> &nbsp;1) root 402 50190.0 10.780 <br>
  &nbsp;&nbsp;&nbsp;2) as.factor(Method)=2 244  7044.0  6.449 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) CoralTotal&lt; 4.955 87  1401.0  3.526 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) CoralTotal&gt;=4.955 157  4488.0  8.069 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10) as.factor(Station)=2,3,6,7,10 122  2593.0  7.075 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11) as.factor(Station)=1,5,9 35  1355.0 11.530 *<br>
  &nbsp;&nbsp;&nbsp;3) as.factor(Method)=1 158 31490.0 17.470 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) as.factor(Station)=3,4 25   781.7  3.157 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) as.factor(Station)=1,2,5,6,7,8,9,10 133 24630.0 20.160 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14) as.factor(Month)=5,7,8,10 94 11590.0 17.090 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;28) as.factor(Station)=1,5,6,7,8 66  6717.0 15.530 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29) as.factor(Station)=2,9,10 28  4328.0 20.780 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15) as.factor(Month)=11 39 10020.0 27.560 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30) CoralTotal&gt;=4.395 27  7647.0 24.810 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;31) CoralTotal&lt; 4.395 12  1713.0 33.740 *</span>
<p>Each line of the text tree contains the following information.
<ol>
  <li>The nodes are numbered in the order they are created. </li>
  <li>The  value following the node number is the split condition: the variable and the value of the variable used to determine the split. </li>
  <li>The third value is the deviance, which for a regression tree is equal to the residual sum of squares.</li>
  <li>The last value is mean of the response variable for all observations assigned to this node. If this value is followed by an asterisk, *, then the node is also a terminal node (leaf).</li>
</ol>
<p>Each split leads to a reduction in total deviance. At the root (null) node the total deviance is 50,190.0. After the first split the total deviance is reported to be </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> 7044.0+31490.0</div>
<span class="style24">[1] 38534</span>
<p>so the deviance has been reduced by splitting on the variable <span class="style8">Method</span>. At each stage of the tree we can sum the deviances at all the terminal nodes and compare it to the deviance at the root node to obtain an R<sup>2</sup>, the fraction of the original total deviance that has been explained by the tree.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> (50190.0-(7044.0+31490.0))/50190.0</div>
<span class="style24">[1] 0.2322</span>
<p><a name="text"></a><a name="margin"></a><a name="usen"></a><a name="plot"></a>Thus splitting the data set into groups based on the variable <span class="style8">Method</span> and using the mean response in each group as the predicted value has explained 23% of the original variability in parrotfish density. We can obtain a graphical summary of the regression tree by plotting the <span class="style4">rpart</span> object and then using the <span class="style4">text</span> function to add labels to the nodes.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(parrot_tree, margin=.1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(parrot_tree, cex=.85, use.n=T)</div>
<br>
<table width="525" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig1.png" width="504" height="225" alt="fig. 1"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 2&nbsp;</strong>&nbsp;Graphical display of the tree</td>
  </tr>
</table>
<p><a name="pretty"></a>The <span class="style221">margin=</span> argument in <span class="style4">plot</span> expands the white space around the tree to prevent truncation of the text that comes next. The<span class="style221"> use.n=</span> argument of <span class="style4">text</span> adds the information about the number of observations occurring at each of the terminal nodes. Notice that <span class="style4">rpart</span> has relabeled the categories of each factor variable as a, b, c, etc. This is  to avoid overlap with  long category names. We can get the actual category levels to display by including the <span class="style221">pretty</span> argument of <span class="style3">text</span>. Setting <span class="style221">pretty=1</span> causes the numeric category levels to be printed.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(parrot_tree, margin=.1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(parrot_tree, cex=.85, use.n=T, pretty=1)</div><br>

<table width="500" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig3pt5.png" width="480" height="240" alt="fig. 3"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 3</strong>&nbsp;&nbsp;&nbsp;Tree with argument pretty=1</td>
  </tr>
</table>

<p><a name="uniform"></a>By default the tree is drawn so that the length of the branches indicate the relative magnitudes of the drops in deviance at each split point. This typically means that the information in the terminal leaves gets crowded together because the changes in deviance there are relatively small. We can correct this by adding the <span class="style221">uniform=T</span> argument to <span class="style4">plot</span> to  obtain trees with equal branches. </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(parrot_tree, margin=.1, uniform=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(parrot_tree, cex=.8, use.n=T, pretty=1)</div>
<br>
<table width="420" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig4a.png" width="385" height="190" alt="fig. 4"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 4</strong>&nbsp;&nbsp;&nbsp;Tree with uniform branching</td>
  </tr>
</table>

<p><a name="branch"></a>We can change the appearance of the branches with the <span class="style221">branch</span> argument. The default choice is <span class="style221">branch=1</span> which yields the rectangular shoulders shown. Choosing <span class="style221">branch=0</span> yields branches with no shoulders. Intermediate values for <span class="style221">branch</span> yield trees with shorter shoulders. I leave out the <span class="style221">pretty</span> argument to obtain a more compact display.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(parrot_tree, margin=.1, uniform=T, branch=0)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> text(parrot_tree, cex=.8, use.n=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(parrot_tree, margin=.1, uniform=T, branch=0.5)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> text(parrot_tree, cex=.8, use.n=T)</div>
<br>
<table width="720" border="0" align="center">
  <tr>
    <td>(a)<img src="../../images/lectures/lecture37/fig3a.png" width="331" height="171" align="top"></td>
    <td>(b)<img src="../../images/lectures/lecture37/fig3b.png" alt="fig. 3b" width="331" height="171" align="top"></td>
  </tr>
  <tr>
    <td colspan="2" class="styleArial"><p span style="padding-left: 48px; text-indent:-48px"><strong>Fig. 5&nbsp;</strong>&nbsp;&nbsp;The effect of varying the branch argument on the displayed tree. (a) branch=0; (b) branch=0.5. Figs. 2, 3, and 4 show branch=1.</td>
  </tr>
</table>
<p><a name="printcp"></a>We can obtain the value of the cost complexity parameter for trees of different sizes with the <span class="style4">printcp</span> function.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">printcp(parrot_tree)</div
>
<span class="style24">Regression tree:<br>
rpart(formula = Parrot ~ CoralTotal + as.factor(Month) + as.factor(Station) + <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;as.factor(Method), data = Bahama)</span>
<p><span class="style24">Variables actually used in tree construction:<br>
  [1] as.factor(Method)  as.factor(Month)   as.factor(Station) CoralTotal </span>
<p><span class="style24">Root node error: 50188/402 = 125</span>
<p><span class="style24">n= 402 </span>
<p> <span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP nsplit rel error xerror  &nbsp;xstd<br>
  1 0.232      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.00   &nbsp;&nbsp;1.00 0.116<br>
  2 0.121      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.77   &nbsp;&nbsp;0.77 0.083<br>
  3 0.060      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.65   &nbsp;&nbsp;0.71 0.075<br>
  4 0.023      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.59   &nbsp;&nbsp;0.67 0.071<br>
  5 0.013      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.56   &nbsp;&nbsp;0.64 0.072<br>
  6 0.011      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.55   &nbsp;&nbsp;0.65 0.073<br>
  7 0.011      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.54   &nbsp;&nbsp;0.64 0.071<br>
  8 0.010      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.53   &nbsp;&nbsp;0.63 0.069</span>
<ol>
  <li>The column labeled <span class="style1">CP</span> is the complexity parameter we discussed in <a href="lecture36.htm#cost">lecture 36</a>. It serves as a penalty term to control tree size and is always monotonic with the number of splits (<span class="style1">nsplit</span>). The smaller the value  of <span class="style1">CP</span>, the more complex will be the tree (the greater the number of splits). </li>
  <li>For a regression tree, the relative error (<span class="style1">rel error</span>) is the average deviance of the current tree divided by the average deviance of the null tree. </li>
  <li>The cross-validation error  (<span class="style1">xerror</span>) is based on a 10-fold cross-validation and is again measured relative to the deviance of the null model. As expected the cross-validation error is greater than the relative error. Using the same data to both fit and test a model results in over-optimistic fit diagnostics.</li>
</ol>
<p><a name="control"></a><a name="rpartc"></a><a name="cp"></a>While relative error is guaranteed to decrease as the tree gets more complex, this will not normally be the case for cross-validation error. Because the cross-validation error is still decreasing in the output shown above, the default tree size is probably too small. We need to refit the model and force <span class="style4">rpart</span> to carry out additional splits. This can be accomplished with the <span class="style221">control</span> argument of <span class="style4">rpart</span>. I use the <span class="style4">rpart.control</span> function to specify a value for <span class="style221">cp=</span> that is smaller than the default value of 0.01. Because the cross-validation error results are random, I use the <span class="style4">set.seed</span> function first to set the seed for the random number stream so that the results obtained are reproducible.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">set.seed(20)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> parrot_tree2 &lt;- rpart(Parrot ~ CoralTotal + as.factor(Month)  + as.factor(Station) + as.factor(Method), data = Bahama, control=rpart.control(cp=.001))</div>
<p>The CP table exists as a component of the <span class="style4">rpart</span> object.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> names(parrot_tree2)</div>
<span class="style24">[1] &quot;frame&quot;     &quot;where&quot;     &quot;call&quot;      &quot;terms&quot;     &quot;cptable&quot;   &quot;splits&quot;    &quot;method&quot;    &quot;parms&quot; <br>
[9] &quot;control&quot;   &quot;functions&quot; &quot;csplit&quot;    &quot;y&quot;         &quot;ordered&quot; </span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> parrot_tree2$cptable</div>
<span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP nsplit rel error xerror    &nbsp;&nbsp;&nbsp;xstd<br>
1  &nbsp;0.232124      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0    &nbsp;&nbsp;&nbsp;1.0000 1.0094 0.11738<br>
2  &nbsp;0.121241      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1    &nbsp;&nbsp;&nbsp;0.7679 0.7880 0.08532<br>
3  &nbsp;0.060104      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2    &nbsp;&nbsp;&nbsp;0.6466 0.7248 0.08104<br>
4  &nbsp;0.023014      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3    &nbsp;&nbsp;&nbsp;0.5865 0.6288 0.06845<br>
5  &nbsp;0.013218      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4    &nbsp;&nbsp;&nbsp;0.5635 0.6327 0.07226<br>
6  &nbsp;0.010802      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5    &nbsp;&nbsp;&nbsp;0.5503 0.6329 0.07345<br>
7  &nbsp;0.010760      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6    &nbsp;&nbsp;&nbsp;0.5395 0.6509 0.07497<br>
8  &nbsp;0.007509      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7    &nbsp;&nbsp;&nbsp;0.5287 0.6416 0.07510<br>
9  &nbsp;0.005288      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8    &nbsp;&nbsp;&nbsp;0.5212 0.6474 0.07387<br>
10 0.004993     &nbsp;&nbsp;&nbsp;&nbsp;10    &nbsp;&nbsp;&nbsp;0.5107 0.6464 0.07350<br>
11 0.003426     &nbsp;&nbsp;&nbsp;&nbsp;11    &nbsp;&nbsp;&nbsp;0.5057 0.6424 0.07367<br>
12 0.001722     &nbsp;&nbsp;&nbsp;&nbsp;12    &nbsp;&nbsp;&nbsp;0.5022 0.6401 0.07318<br>
13 0.001369     &nbsp;&nbsp;&nbsp;&nbsp;13    &nbsp;&nbsp;&nbsp;0.5005 0.6399 0.07202<br>
14 0.001124     &nbsp;&nbsp;&nbsp;&nbsp;14    &nbsp;&nbsp;&nbsp;0.4991 0.6439 0.07249<br>
15 0.001000     &nbsp;&nbsp;&nbsp;&nbsp;15    &nbsp;&nbsp;&nbsp;0.4980 0.6440 0.07249</span>
<p><a name="plotcp"></a>From the output it appears that <span class="style1">xerror</span> has achieved an interior minimum. We can obtain an informative graphical display of the <em>c<sub>p</sub></em> table with the <span class="style4">plotcp</span> function.
<div class="style10" style="padding-left: 30px; text-indent:-30px">plotcp(parrot_tree2)</div>
<br>
<table width="550" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig4.png" width="499" height="320" alt="fig. 4"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 6 </strong>&nbsp;Plot of CP table. The dotted line denotes the upper limit of the one standard deviation rule.</td>
  </tr>
</table>
<p>From the graph it would appear that the minimum cross-validation error occurred for the fourth tree listed in the CP table that had a total of 4 leaves. We can verify this by just examining the table by eye or more formally as follows.
<div class="style15" style="padding-left: 30px; text-indent:-30px">#minimum cross-validation error</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">min(parrot_tree2$cptable[,&quot;xerror&quot;])</div>
<span class="style24"> [1] 0.6288</span>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #location of minimum in CP table</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> which.min(parrot_tree2$cptable[,&quot;xerror&quot;])</div>
<span class="style24"> 4 <br>
4</span>
<div class="style15" style="padding-left: 30px; text-indent:-30px"># the tree with the minimum cross-validation error</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">parrot_tree2$cptable[4,]</div>
<span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP    &nbsp;nsplit rel error    &nbsp;xerror      &nbsp;&nbsp;&nbsp;xstd <br>
0.02301   3.00000   &nbsp;&nbsp;0.58653   0.62884   0.06845 </span>
<p>So, if we were to use the tree that minimized the cross-validation error we would choose a tree with 3 splits. As was noted in <a href="lecture36.htm#cross">lecture 36</a>, the problem with such a choice is that the cross-validation error is a random quantity. There is no guarantee that if we were to fit the sequence of trees again using a different random seed that the same tree would minimize the cross-validation error.
<p> <a name="prune"></a>A more robust alternative to minimum cross-validation error is to use the one standard deviation rule: choose the smallest tree whose cross-validation error is within one standard error of the minimum. Using this rule we would still end up with the same tree. The first tree whose point estimate of the cross-validation error falls within the &plusmn; 1 <span class="style1">xstd</span> of the minimum, is the minimum tree itself of size 4.
I extract the <span class="style1">CP</span> value of this tree and refit the tree using the <span class="style4">prune</span> function on the current tree object.
<div class="style10" style="padding-left: 30px; text-indent:-30px"> cp.choice &lt;- parrot_tree2$cptable[4,&quot;CP&quot;]</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> cp.choice</div>
<span class="style24"> [1] 0.02301</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> pruned.tree &lt;- prune(parrot_tree2, cp=cp.choice)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> pruned.tree</div>
<span class="style24"> n= 402 </span>
<p><span class="style24">node), split, n, deviance, yval<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* denotes terminal node </span>
<p><span class="style24"> &nbsp;1) root 402 50190.0 10.780 <br>
  &nbsp;&nbsp;&nbsp;2) as.factor(Method)=2 244  7044.0  6.449 *<br>
  &nbsp;&nbsp;&nbsp;3) as.factor(Method)=1 158 31490.0 17.470 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) as.factor(Station)=3,4 25   781.7  3.157 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) as.factor(Station)=1,2,5,6,7,8,9,10 133 24630.0 20.160 <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14) as.factor(Month)=5,7,8,10 94 11590.0 17.090 *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15) as.factor(Month)=11 39 10020.0 27.560 *</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(pruned.tree, margin=0.1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(pruned.tree ,cex=.9, use.n=T, pretty=1)</div>
<br>
<table width="425" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig7a.png" width="380" height="190" alt="fig. 7"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 7</strong> &nbsp;The pruned tree</td>
  </tr>
</table>
<p>This result is probably the researcher's worst nightmare. None of the important predictors turn out to be biological variables. Instead we see that the survey method (point counts versus transect) is the most important predictor of parrotfish density. The right branch consisting of only point counts then divides out best by the location at which the sample was taken (station) and six of these stations are then split by the month of the sample.</p>
<p>The <span class="style3">predict</span> function works with tree objects. For a regression tree it returns the mean  at the leaf where  the observation is assigned.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> predict(pruned.tree)[1:20]</div>
<span class="style24">  &nbsp;[1] 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394<br>
  &nbsp;[9] 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394 17.09394<br>
  [17] 27.55513 27.55513 27.55513 27.55513</span>

<p>Just like the <span class="style4">rpart</span> object, the <span class="style4">prune</span> object contains quite a bit of information.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> names(pruned.tree)</div>
<span class="style24">[1] &quot;frame&quot;     &nbsp;&nbsp;&quot;where&quot;     &nbsp;&nbsp;&nbsp;&nbsp;&quot;call&quot;      &nbsp;&nbsp;&quot;terms&quot;     &quot;cptable&quot;   &quot;splits&quot;    &quot;method&quot;    &quot;parms&quot; <br>
[9] &quot;control&quot;   &quot;functions&quot; &quot;csplit&quot;    &quot;y&quot;         &nbsp;&nbsp;&nbsp;&nbsp;&quot;ordered&quot; </span>
<p>The <span class="style32">$where</span> component indicates to which leaf the different observations have been assigned.<br>
<div class="style10" style="padding-left: 30px; text-indent:-30px">pruned.tree$where</div>
<span class="style24">&nbsp; [1] 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2<br>
&nbsp;[39] 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7<br>
&nbsp;[77] 7 7 7 7 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 2 2<br>
[115] 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2<br>
[153] 2 2 2 2 2 2 2 2 6 6 6 6 6 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6<br>
[191] 6 6 6 6 6 6 6 6 6 6 6 6 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2<br>
[229] 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6<br>
[267] 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2<br>
[305] 2 2 2 2 2 2 2 2 2 2 2 2 6 6 6 6 2 2 2 2 2 2 2 6 6 6 6 6 6 6 7 7 7 7 7 7 2 2<br>
[343] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6 6 7 7 7 7 7 7 7 2 2 2<br>
[381] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> unique(pruned.tree$where)</div>
<span class="style24"> [1] 6 7 2 4</span>
<p>The numbers themselves correspond to row numbers in the <span class="style32">$frame</span> component that defines the final tree. <br>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> pruned.tree$frame</div>
<span class="style24"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var   &nbsp;&nbsp;n  &nbsp;wt     &nbsp;&nbsp;&nbsp;&nbsp;dev   &nbsp;&nbsp;yval complexity ncompete nsurrogate<br>
1   &nbsp;&nbsp;as.factor(Method) 402 402 50188.3 10.781   &nbsp;&nbsp;0.232124        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3<br>
2              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;leaf&gt; 244 244  &nbsp;7044.2  &nbsp;6.449   &nbsp;&nbsp;0.023014        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0<br>
3  &nbsp;as.factor(Station) 158 158 31494.2 17.471   &nbsp;&nbsp;0.121241        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1<br>
6              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;leaf&gt;  &nbsp;25  &nbsp;25   &nbsp;&nbsp;781.7  &nbsp;3.157   &nbsp;&nbsp;0.001722        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0<br>
7    &nbsp;&nbsp;&nbsp;as.factor(Month) 133 133 24627.6 20.162   &nbsp;&nbsp;0.060104        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2<br>
14             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;leaf&gt;  &nbsp;94  &nbsp;94 11587.6 17.094   &nbsp;&nbsp;0.010802        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0<br>
15             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;leaf&gt;  &nbsp;39  &nbsp;39 10023.5 27.555   &nbsp;&nbsp;0.013218        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span>
<p>Notice that rows 2, 4, 6, and 7 are labeled as leaves but have row names 2, 6, 14, and 15. The row names in the frame are the actual left-to-right positions of the leaves in the tree. The missing numbers correspond to splits and leaf locations that don't appear in the pruned tree. We can use all this information to display box plots in the same order as the left-to-right positions of the leaves of the pruned tree. I adjust the margins of each graph with the <span class="style221">mar</span> argument of <span class="style104">par</span> to try to position the boxplots  right below the corresponding leaf of the tree. 
  I use the contents of the <span class="style32">$where</span> component to group the observations  by their final leaf assignment.
<div class="style10" style="padding-left: 30px; text-indent:-30px"></div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #create a factor for leaf positions</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> where &lt;- factor(pruned.tree$where)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #calculate sample sizes as a check</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> n &lt;- tapply(Bahama$Parrot, where, length)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #place boxplot directly below tree and remove some white space </div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mfrow=c(2,1))</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #save old margin settings</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> oldmar &lt;- par(&quot;mar&quot;)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #margins for tree</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> par(mar=c(0,4.1,1.1,1.1))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(pruned.tree, margin=.2)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> text(pruned.tree, cex=.8, use.n=T, pretty=1)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #margins for boxplot</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mar=c(2.1,5.1,0,1.8))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> boxplot(Bahama$Parrot~where, varwidth=T, pars=list(axes=F))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">axis(2)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">mtext(side=1,line=.5, text=paste(&quot;n=&quot;,n), at=1:4, cex=.9)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #restore original margins</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> par(mar = oldmar)</div>
<br>
<table width="425" border="0" align="center">
  <tr>
    <td><div align="center"><img src="../../images/lectures/lecture37/fig8a.png" width="390" height="370" alt="fig. 8"></div></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 8&nbsp;</strong>&nbsp;Pruned tree with box plots of the distributions of the response at the terminal nodes</td>
  </tr>
</table>
<p>Based on  the box plots it appears that the first two splits of the tree have managed to pull out most of surveys that yielded the lowest densities of parrotfish. 
<p><a name="partykit"></a>The <span class="style19">partykit</span> package of R produces enhanced displays of regression and classification trees. It does its own version of Fig. 8. To use it we need to convert the tree created by <span class="style3">rpart</span> into a party object with the <span class="style3">as.party</span> function. I pass an additional argument, <span class="style221">id=FALSE</span>, to the <span class="style3">plot</span> function to suppress displaying the node number of each tree.
<div class="style10" style="padding-left: 30px; text-indent:-30px">library(&quot;partykit&quot;)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(as.party(pruned.tree), tp_args=list(id=FALSE))</div><br>
<table width="575" border="0" align="center">
  <tr>
    <td><div align="center"><img src="../../images/lectures/lecture37/fig9a.png" width="510" height="330" alt="fig. 9"></div></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 9&nbsp;</strong>&nbsp;Regression tree diagram produced by the partykit package</td>
  </tr>
</table>

<h2><a name="classification"></a>Classification trees</h2>
<p><a name="minsplit"></a><a name="parms"></a>Classification trees are constructed the same way as regression trees, so I skip over most of the preliminaries. The data in the Ditch data set are clearly heterogeneous but perhaps we can ignore this because we're treating the annual measurements at each site as  replicates of that site. I start with a small value for <span class="style221">cp</span> so that the initial tree is as large as possible. Because we don't have much data (only 48 observations) I also set a lower value for the <span class="style221">minsplit</span> criterion. By default it's set at 20 so that any group with fewer than 20 observations in it would not be split further. (Note: by default <span class="style221">minbucket</span>, the minimum number of observations allowed to form a terminal node, is set to  <span class="style1">minbucket = minsplit/3</span> so reducing <span class="style221">minsplit</span> also decreases <span class="style221">minbucket</span>.) The default split criterion is the Gini index. This can be changed to the entropy measure. To carry this out we would need to add a <span class="style221">parms</span> argument to the <span class="style4">rpart</span> call: <span class="style221">parms=list(split=&quot;information&quot;)</span>.
<p>To avoid typing all of the variable names in the model formula I use the <span class="style1">~.</span> notation and remove those variables that should not be in the model by not including them in the <span class="style221">data</span> argument. To obtain a classification tree the response variable needs to be a factor. Alternatively one can add the argument <span class="style221">method='class</span>' to obtain a classification tree.
<div class="style10" style="padding-left: 30px; text-indent:-30px"> set.seed(50) </div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> ditch_tree &lt;- rpart(factor(Site)~., data=Ditch[,c(1,4:18)], control=rpart.control(cp=0.001, minsplit=15))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">ditch_tree</div>
<span class="style24"> n= 48 </span>
<p><span class="style24">node), split, n, loss, yval, (yprob)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* denotes terminal node </span>
<p><span class="style24"> &nbsp;1) root 48 38 1 (0.21 0.19 0.21 0.21 0.19) <br>
  &nbsp;&nbsp;&nbsp;2) Total_Calcium&gt;=118 25 16 5 (0.32 0.28 0 0.04 0.36) <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) Conductivity&lt; 1505 11  6 1 (0.45 0.45 0 0.091 0) *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) Conductivity&gt;=1505 14  5 5 (0.21 0.14 0 0 0.64) *<br>
  &nbsp;&nbsp;&nbsp;3) Total_Calcium&lt; 118 23 13 3 (0.087 0.087 0.43 0.39 0) <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) Depth&gt;=0.505 8  0 3 (0 0 1 0 0) *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7) Depth&lt; 0.505 15  6 4 (0.13 0.13 0.13 0.6 0) <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14) Conductivity&lt; 622.5 5  3 1 (0.4 0 0.4 0.2 0) *<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15) Conductivity&gt;=622.5 10  2 4 (0 0.2 0 0.8 0) *</span>
<p>The output resembles that of the regression tree with the following differences. </p>
<ol>
  <li>Because the response variable consists of multiple categories what's reported are the proportions of observations that occur in each of the categories (<span class="style32">yprob</span>).</li>
  <li>The value labeled <span class="style32">yval</span> is the category with the highest predicted probability.</li>
  <li>The deviance column is replaced by something called &quot;<span class="style32">loss</span>&quot;. The <span class="style32">loss</span> is the number of misclassified observations. It's the number of observations assigned to that leaf that are not equal to <span class="style32">yval</span>.</li>
</ol>
<p>I next display a graph of the tree. </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(ditch_tree, mar=0.1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(ditch_tree, use.n = T, cex = .9)</div>
<br>
<table width="400" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig7.png" width="332" height="256" alt="fig. 7"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 10</strong> &nbsp;&nbsp;A classification tree</td>
  </tr>
</table>
<p>At each leaf we have the predicted category for the members of that leaf using a simple majority rule. The <span class="style221">use.n=T</span> argument caused the actual number of observations in the five categories to  be displayed below the prediction.</p>
<p>I next generate a plot of the cross-validation error for different values of cost complexity parameter.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plotcp(ditch_tree)</div>
<br>
<table width="500" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig8.png" width="434" height="376" alt="fig. 8"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 11</strong> &nbsp;&nbsp;The cross-validation error for a sequence of classification trees</td>
  </tr>
</table>
<p>The result are fairly unambiguous. A tree with four leaves is best. I examine the CP table.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">ditch_tree$cptable</div>
<span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP nsplit rel error xerror    &nbsp;&nbsp;&nbsp;xstd<br>
1 0.23684      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0    &nbsp;&nbsp;&nbsp;1.0000 1.1842 0.04413<br>
2 0.18421      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1    &nbsp;&nbsp;&nbsp;0.7632 1.1842 0.04413<br>
3 0.13158      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2    &nbsp;&nbsp;&nbsp;0.5789 1.0526 0.06795<br>
4 0.02632      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3    &nbsp;&nbsp;&nbsp;0.4474 0.7368 0.08989<br>
5 0.00100      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4    &nbsp;&nbsp;&nbsp;0.4211 0.7368 0.08989</span>
<p>I prune the tree using the optimal value of CP and display the results.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">myprune &lt;- prune(ditch_tree, cp=ditch_tree$cptable[4,&quot;CP&quot;])</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(myprune, margin=.1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">text(myprune, use.n = T, cex = .9)</div>
<br>
<table width="400" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig9.png" width="332" height="256" alt="fig. 9"></td>
  </tr>
  <tr>
    <td class="styleArial"><strong>Fig. 12</strong> &nbsp;&nbsp;The pruned tree</td>
  </tr>
</table>
<p>The <span class="style3">predict</span> function applied to classification trees reports the  category probabiities for the leaf that an  observation is assigned.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> predict(myprune)[1:10,]</div>
<span class="style24">  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5<br>
  &nbsp;[1,] 0.1333333 0.1333333 0.1333333 0.60000000 0.0000000<br>
  &nbsp;[2,] 0.4545455 0.4545455 0.0000000 0.09090909 0.0000000<br>
  &nbsp;[3,] 0.1333333 0.1333333 0.1333333 0.60000000 0.0000000<br>
  &nbsp;[4,] 0.2142857 0.1428571 0.0000000 0.00000000 0.6428571<br>
  &nbsp;[5,] 0.2142857 0.1428571 0.0000000 0.00000000 0.6428571<br>
  &nbsp;[6,] 0.4545455 0.4545455 0.0000000 0.09090909 0.0000000<br>
  &nbsp;[7,] 0.4545455 0.4545455 0.0000000 0.09090909 0.0000000<br>
  &nbsp;[8,] 0.4545455 0.4545455 0.0000000 0.09090909 0.0000000<br>
  &nbsp;[9,] 0.4545455 0.4545455 0.0000000 0.09090909 0.0000000<br>
[10,] 0.2142857 0.1428571 0.0000000 0.00000000 0.6428571</span>
<p>The default <span class="style19">partykit</span> display for classification trees  is a bar chart for response variables with more than two categories. Based on the displayed frequency counts in the leaves it's clear that we've classified one group perfectly and two others fairly well. </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">library(&quot;partykit&quot;)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">plot(as.party(myprune), tp_args=list(id=FALSE))</div><br>
<table width="575" border="0" align="center">
  <tr>
    <td><div align="center"><img src="../../images/lectures/lecture37/fig12a.png" width="500" height="340" alt="fig. 12"></div></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 13&nbsp;</strong>&nbsp;Classification tree diagram produced by the partykit package</td>
  </tr>
</table>

<p><a name="mosaic"></a>Another way we can summarize the classification results graphically is with a mosaic plot, which replaces the box plots for a regression tree and the bar charts produced by the <span class="style19">partykit</span> package. </p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mfrow=c(2,1))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mar=c(0.5,2.1,0.5,0))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> plot(myprune, margin=.3)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> text(myprune, use.n = T, cex = .9)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(xpd=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mar=c(2.1,3.1,0.1,1))</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> out.t &lt;- table(myprune$where, Ditch$Site)</div>
<div class="style15" style="padding-left: 30px; text-indent:-30px"> #remove labels for where categories</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> rownames(out.t) &lt;- rep('',4)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> mosaicplot(out.t, main='', xlab='', las=1)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(xpd=F)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mar=c(4.1,5.1,2.1,1.1)) </div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">par(mfrow=c(1,1))</div>
</p>
<table width="425" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig10a.png" width="410" height="330" alt="fig. 10"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 14</strong> &nbsp;&nbsp;Classification tree and corresponding mosaic plot</td>
  </tr>
</table>
<p>In a mosaic plot the categories that don't appear at a leaf are shown with dashed lines in the appropriate positions. The width of the boxes reflect the number of observations assigned to the four leaves of the tree.</p>
<p><a name="dotchart"></a>The first split of the classification tree was based on calcium levels. We can graphically assess how well this split discriminated the sites with a dot chart in which  a line is superimposed at the calcium split value. Each site type is displayed with a different symbol type.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">dotchart(Ditch$Total_Calcium,&nbsp; pch = Ditch$Site,
  xlab = &quot;Range&quot;, ylab = &quot;Sample&quot;,
  main = &quot;Total Calcium&quot;)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px">abline(v=118,lty=2,col=2)</div>
<br>
<table width="500" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig11.png" width="438" height="371" alt="fig. 11"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 44px; text-indent:-44px"><strong>Fig. 15</strong>&nbsp;&nbsp; Dot plot of the primary split variable, Total_Calcium</td>
  </tr>
</table>
<p>From the graph it's pretty clear that total calcium level does a very good job at discriminating two groups of sites. Sites 1, 2, and 5 look very different from sites 3 and 4. For most of the sites only a couple of years  end up being classified into the wrong group, while  site 3 has been classified perfectly.</p>
<p>So far we've been ignoring the <span class="style4">summary</span> results from an <span class="style4">rpart</span> run because the output is so copious. It contains an entire summary of the tree fitting process. One useful portion of the <span class="style4">summary</span> output is the description of surrogate splits. Below I show this information for the first split at <span class="style8">Total_Calcium</span>.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">summary(myprune)</div>
<span class="style24"> Call:<br>
rpart(formula = factor(Site) ~ ., data = Ditch[, c(1, 4:18)], <br>
&nbsp;&nbsp;&nbsp;&nbsp;control = rpart.control(cp = 0.001, minsplit = 15))<br>
&nbsp;n= 48 </span>
<p> <span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP nsplit rel error xerror    &nbsp;&nbsp;&nbsp;xstd<br>
  1 0.23684      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0    &nbsp;&nbsp;&nbsp;1.0000 1.1842 0.04413<br>
  2 0.18421      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1    &nbsp;&nbsp;&nbsp;0.7632 1.1842 0.04413<br>
  3 0.13158      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2    &nbsp;&nbsp;&nbsp;0.5789 1.0526 0.06795<br>
  4 0.02632      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3    &nbsp;&nbsp;&nbsp;0.4474 0.7368 0.08989</span>
<p><span class="style24">Node number 1: 48 observations,    complexity param=0.2368<br>
  &nbsp;&nbsp;predicted class=1  expected loss=0.7917<br>
  &nbsp;&nbsp;&nbsp;&nbsp;class counts:    &nbsp;&nbsp;&nbsp;10     &nbsp;&nbsp;&nbsp;&nbsp;9    &nbsp;&nbsp;&nbsp;10    &nbsp;&nbsp;&nbsp;10     &nbsp;&nbsp;&nbsp;&nbsp;9<br>
  &nbsp;probabilities: &nbsp;&nbsp;0.208 0.188 0.208 0.208 0.188 <br>
  left son=2 (25 obs) right son=3 (23 obs)<br>
  </span><span class="style25">Primary splits:</span><span class="style24"><br>
  &nbsp;&nbsp;&nbsp;&nbsp;Total_Calcium &lt; 118   &nbsp;&nbsp;to the right, improve=6.392, (0 missing)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Chloride      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 71    &nbsp;&nbsp;&nbsp;to the right, improve=6.142, (0 missing)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Sulphate      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 205   &nbsp;&nbsp;to the right, improve=5.792, (0 missing)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Conductivity  &nbsp;&lt; 703   &nbsp;&nbsp;to the right, improve=5.125, (0 missing)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Depth         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 0.505 to the right, improve=4.807, (4 missing)<br>
  </span><span class="style25">Surrogate splits:</span><span class="style24"><br>
  &nbsp;&nbsp;&nbsp;&nbsp;Chloride            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 71    &nbsp;&nbsp;&nbsp;to the right, agree=0.917, adj=0.826, (0 split)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Conductivity        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 722.5 to the right, agree=0.896, adj=0.783, (0 split)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Sulphate            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 261   &nbsp;&nbsp;to the right, agree=0.875, adj=0.739, (0 split)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Ammoniacal_Nitrogen &lt; 0.25  &nbsp;to the right, agree=0.812, adj=0.609, (0 split)<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Total_Zinc          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt; 0.035 to the right, agree=0.708, adj=0.391, (0 split)</span>
<p>The section labeled &quot;Primary splits&quot; lists the top five options that were considered for forming the first split. From this we can see that <span class="style8">Total_Calcium</span> was not a clear winner. <span class="style8">Chloride</span>, the second choice, does nearly as well in decreasing impurity. If the goal in building a classification tree is to screen out variables for a subsequent parametric regression, then one might  consider including some of competitive primary split variables in the parametric regression too.</p>
<p>The section labeled Surrogate splits considers other splits that most closely agree with the group allocations obtained with <span class="style8">Total_Calcium</span> &lt; 118. For instance we see that choosing to split on <span class="style8">Chloride</span> &lt; 71 instead of <span class="style8">Total_Calcium</span> &lt; 118 would have yielded a classification of observations at this split that is 91.7% in agreement. This can be useful in predicting new observations that have missing values for the primary split variable. So if a new variable did not have a value for <span class="style8">Total_Calcium</span> we could use <span class="style8">Chloride</span> instead and most likely achieve a similar classification to what we would have if we had a value for <span class="style8">Total_Calcium</span>.</p>
<h2><a name="forest"></a>Random forests</h2>
<p>Two R packages that implement random forests are  <span class="style19">randomForest</span> and  <span class="style19">party</span>. The <span class="style19">randomForest</span> package is an R port of the Fortran code of the original implementation of random forests by Leo Breiman. The <span class="style19">party</span> package uses conditional inference trees that  supposedly  minimize the bias that random forests can exhibit with correlated variables. The function in the <span class="style19">randomForest</span> package for fitting random forests is <span class="style3">randomForest</span>. It uses a formula interface just like <span class="style3">rpart</span>.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> library(randomForest)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> rf &lt;- randomForest(factor(Site)~., data=Ditch[,c(1,4:18)],)</div>
<span class="style24">  Error in na.fail.default(list(`factor(Site)` = c(1L, 1L, 1L, 1L, 1L, 1L,&nbsp; : <br>
&nbsp; missing values in object</span>
<p><a name="importance"></a>Unlike <span class="style3">rpart</span> we need to tell the <span class="style3">randomForest</span> function how to deal with missing values because <span class="style3">randomForest</span> needs to construct subsets of the variables when building individual trees. A standard choice is <span class="style221">na.action=na.roughfix</span>. This imputes missing values using either the median of the non-missing observations (regression trees) or the most frequent category (classification trees). I add this argument as well as <span class="style221">importance = T</span> in order to obtain importance statistics.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> rf &lt;- randomForest(factor(Site)~., data=Ditch[,c(1,4:18)], na.action=na.roughfix, importance=T)</div>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> names(rf)</div>
<span class="style24">  &nbsp;[1] &quot;call&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&quot;type&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;predicted&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;err.rate&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
  &nbsp;[5] &quot;confusion&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;votes&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;oob.times&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;classes&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
  &nbsp;[9] &quot;importance&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;importanceSD&quot;&nbsp;&nbsp;&nbsp; &quot;localImportance&quot; &quot;proximity&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
  [13] &quot;ntree&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;mtry&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;forest&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;y&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
[17] &quot;test&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;inbag&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;terms&quot;&nbsp;&nbsp;&nbsp; </span>
<p>If we print the object we get details about the fit.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> rf</div>

<span class="style24">Call:<br>
  &nbsp;randomForest(formula = factor(Site) ~ ., data = Ditch[, c(1,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4:18)], importance = T, na.action = na.roughfix) <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Type of random forest: classification<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number of trees: </span><span class="style25">500</span><span class="style24"><br>
  No. of variables tried at each split: </span><span class="style25">3
  </span>
<p><span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="style25">OOB estimate of&nbsp; error rate: 47.92%</span><span class="style24"><br>
  Confusion matrix:<br>
  &nbsp; 1 2 3 4 5 class.error<br>
  1 1 4 2 0 3&nbsp;&nbsp; 0.9000000<br>
  2 5 3 0 0 1&nbsp;&nbsp; 0.6666667<br>
  3 0 0 7 2 1&nbsp;&nbsp; 0.3000000<br>
  4 1 0 2 7 0&nbsp;&nbsp; 0.3000000<br>
  5 1 0 0 1 7&nbsp;&nbsp; 0.2222222  &nbsp;</span>

<p>From the printout we see that by default the forest was built from 500 trees each of which is a bootstrap sample from the actual data. Observations that are left out of the bootstrap sample form the &quot;out of bag&quot; (OOB) set. The OOB observations from each tree were used to assess fit. The printout reports that at each split point a random sample of three predictors (= the floor of the square root of the total number of predictors) was obtained and used to determine the best split. </p>
<p>The error rate of 47.92% can  be calculated from the confusion matrix shown at the bottom of the output. The rows of the confusion matrix correspond to the actual categories while the columns are the predicted categories. The predictions of the OOB observations are based on the majority opinion of the 500 trees. Entries on the diagonal are the number of times the random forest made the correct prediction. Thus we see that in site 1 only one of the observations was correctly predicted by the forest; the other nine were incorrectly assigned to other categories. The best prediction rate is  for site 5 where 7 of the 9 observations are correctly classified by the random forest.</p>
<p>By specifying <span class="style221">importance=T</span> in the function call we obtain measures of each variable's importance to the classification.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> rf$importance</div>
  <span class="style24">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4<br>
  Depth&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0028000000&nbsp; 0.025466667&nbsp; 0.098857143&nbsp; 0.044647619<br>
  pH&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0102142857 -0.013457143 -0.007304762 -0.002835714<br>
  Conductivity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0202833333&nbsp; 0.005333333&nbsp; 0.079966667&nbsp; 0.031947619<br>
  BOD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0029476190 -0.003266667 -0.001033333 -0.004314286<br>
  Ammoniacal_Nitrogen&nbsp;&nbsp;&nbsp;&nbsp; -0.0077190476 -0.008735714 -0.001833333 -0.003407143<br>
  Total_Oxidised_Nitrogen -0.0089833333&nbsp; 0.008333333 -0.001319048&nbsp; 0.004400000<br>
  Suspended_Solids&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0202666667&nbsp; 0.018619048&nbsp; 0.020009524&nbsp; 0.016200000<br>
  Chloride&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0059333333&nbsp; 0.015628571&nbsp; 0.085352381&nbsp; 0.045450000<br>
  Sulphate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0013380952&nbsp; 0.007666667&nbsp; 0.041842857&nbsp; 0.062373810<br>
  Total_Calcium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0134666667 -0.013161905&nbsp; 0.098500000&nbsp; 0.064019048<br>
  Total_Zinc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0121166667&nbsp; 0.032247619&nbsp; 0.041219048&nbsp; 0.006061905<br>
  Total_Cadmium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0016000000 -0.000200000 -0.005266667 -0.001685714<br>
  Total_Lead&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0046333333&nbsp; 0.028266667&nbsp; 0.005366667&nbsp; 0.009885714<br>
  Total_Nickel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0006333333 -0.001833333 -0.001185714 -0.003500000<br>
  Total_Phosphate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0057190476 -0.007200000&nbsp; 0.027109524&nbsp; 0.161309524<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5 </span><span class="style25">MeanDecreaseAccuracy</span> <span class="style25">MeanDecreaseGini</span><span class="style24"><br>
Depth&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0020190476&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0306509511&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.4146216<br>
pH&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0113476190&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0066050167&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.7914344<br>
Conductivity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1069190476&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0359485513&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1764033<br>
BOD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0033000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0014124502&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.5922467<br>
Ammoniacal_Nitrogen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0988000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0138814218&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3691919<br>
Total_Oxidised_Nitrogen -0.0012619048&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0006801351&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.9740028<br>
Suspended_Solids&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0006666667&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0058266886&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.7005667<br>
Chloride&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0797619048&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0406627907&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3421930<br>
Sulphate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0101000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0230129595&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.4430097<br>
Total_Calcium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0588571429&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0366480276&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.7074724<br>
Total_Zinc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0099857143&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0146729988 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.1329549<br>
Total_Cadmium&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0014142857&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0016455866&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.4718458<br>
Total_Lead&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0136666667&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0101774810&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3720880<br>
Total_Nickel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0009333333&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.0019895049&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.6116379<br>
Total_Phosphate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0130333333&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.0365652276&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2338879</span>
<p>The two columns labeled MeanDecreaseAccuracy and MeanDecreaseGini contain the two importance measures discussed in <a href="lecture36.htm#summarizing">lecture 36</a>. MeanDecreaseAccuracy measures how much the prediction is affected if the values of a predictor are randomly permuted among the other observations in the OOB set. A good way to display these results is with a dot chart in which the variables are sorted by their importance.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px">dotchart(sort(rf$importance[,6]))</div><br>
<table width="500" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig13a.png" width="430" height="300" alt="Fig. 15"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 60px; text-indent:-60px"><strong>Fig. 16</strong>&nbsp;&nbsp; Variable importance as indicated by the mean decrease in accuracy</td>
  </tr>
</table>
<p>The variables appear to fall roughly into   groups with the first five or six variables being clearly more important than the rest. It's useful to compare this picture to the one we get using the importance measure based on the Gini index.</p>

<div class="style10" style="padding-left: 30px; text-indent:-30px">dotchart(sort(rf$importance[,7]))</div><br>

<table width="500" border="0" align="center">
  <tr>
    <td><img src="../../images/lectures/lecture37/fig13b.png" width="430" height="300" alt="Fig. 16"></td>
  </tr>
  <tr>
    <td class="styleArial"><p span style="padding-left: 60px; text-indent:-60px"><strong>Fig. 17</strong>&nbsp;&nbsp; Variable importance as determined by the mean decrease in Gini index</td>
  </tr>
</table>
<p>While there has been a change in the order of the variables, the first six ranked variables using either importance measure are the same.</p>
<p>The <span class="style3">predict</span> function  works with <span class="style3">randomForest</span> objects. By default, the <span class="style3">predict</span> function returns the majority vote of the 500 trees for the times when that the observation was OOB.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> predict(rf)</div>
<span class="style24">  &nbsp;1&nbsp; 2&nbsp; 3&nbsp; 4&nbsp; 5&nbsp; 6&nbsp; 7&nbsp; 8&nbsp; 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 <br>
  &nbsp;3&nbsp; 2&nbsp; 3&nbsp; 5&nbsp; 5&nbsp; 2&nbsp; 1&nbsp; 5&nbsp; 2&nbsp; 2&nbsp; 1&nbsp; 2&nbsp; 1&nbsp; 2&nbsp; 1&nbsp; 1&nbsp; 2&nbsp; 1&nbsp; 5&nbsp; 3&nbsp; 3&nbsp; 3&nbsp; 5&nbsp; 3&nbsp; 3&nbsp; 3&nbsp; 4 <br>
  28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 <br>
  &nbsp;3&nbsp; 4&nbsp; 4&nbsp; 4&nbsp; 4&nbsp; 4&nbsp; 4&nbsp; 4&nbsp; 3&nbsp; 3&nbsp; 4&nbsp; 1&nbsp; 1&nbsp; 5&nbsp; 4&nbsp; 5&nbsp; 5&nbsp; 5&nbsp; 5&nbsp; 5&nbsp; 5 <br>
Levels: 1 2 3 4 5</span>
<p>If <span class="style221">type='prob'</span> is added as an argument we get instead the proportion of times that a given observation was assigned to the different categories while OOB.</p>
<div class="style10" style="padding-left: 30px; text-indent:-30px"> predict(rf,type='prob')[1:10,]</div>
<span class="style24">  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5<br>
  1&nbsp; 0.13513514 0.1783784 0.43243243 0.24864865 0.005405405<br>
  2&nbsp; 0.17277487 0.7172775 0.01570681 0.07853403 0.015706806<br>
  3&nbsp; 0.17112299 0.1016043 0.39037433 0.32085561 0.016042781<br>
  4&nbsp; 0.22784810 0.1075949 0.01265823 0.03797468 0.613924051<br>
  5&nbsp; 0.23936170 0.2074468 0.01063830 0.02127660 0.521276596<br>
  6&nbsp; 0.25714286 0.4914286 0.06285714 0.07428571 0.114285714<br>
  7&nbsp; 0.33701657 0.2983425 0.19889503 0.03867403 0.127071823<br>
  8&nbsp; 0.29729730 0.1783784 0.02162162 0.02702703 0.475675676<br>
  9&nbsp; 0.11728395 0.3580247 0.18518519 0.22839506 0.111111111<br>
10 0.03763441 0.7688172 0.00000000 0.01075269 0.182795699</span>
<h2>Cited References</h2>
<ul>
  <li>
    <p><a name="zuur"></a>Zuur, Alain F., Elena N. Ieno, and Graham M. Smith. 2007. <em>Analysing Ecological Data.</em> Springer, New York. <a href="http://www.springerlink.com/content/g6632j/">UNC e-book</a></p>
  </li>
</ul>
<p align="center"><a href="../../index.html">Course Home Page</a></p>
<hr align="center" width="75%">
<!--Standard footer follows -->
<table width="650" border="3" cellspacing="2" cellpadding="2" align=
"CENTER">
  <tr bgcolor="#CCCCCC">
    <td width="100%"><font size=-1>Jack Weiss<br>
      <i>Phone: </i>(919) 962-5930<br>
      <i>E-Mail:</i> jack_weiss@unc.edu<br>
      <i>Address: </i>Curriculum for the Environment and Ecology, Box 3275, University of North Carolina, Chapel Hill, 27599<br>
      Copyright &copy; 2012<br>
      Last Revised--April 17, 2012<br>
      URL: <a href="lecture37.htm#lecture37" target="_self">https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/lecture37.htm</a></font></td>
  </tr>
</table>
<p align="center">&nbsp;</p>
</body>
</html>
