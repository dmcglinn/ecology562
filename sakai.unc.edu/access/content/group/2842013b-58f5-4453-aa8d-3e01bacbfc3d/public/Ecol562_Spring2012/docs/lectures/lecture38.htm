<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Lecture 38&mdash;Monday, April 16, 2012</title>
<link rel="stylesheet" type="text/css" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/green.css" title="green" /> 
<link rel="stylesheet" type="text/css" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/calendar.css" title="calendar" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/purple.css" title="purple" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/large.css" title="large" /> 
<link rel="alternate stylesheet" type="text/css" media="all" href="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/css/reverse.css" title="reverse" /> 
<!-- the @import method only works from 5.0 and upwards  -->
<!-- so, using @import would "hide" the more sophisticated sheet from < 5.0 browsers -->
<!-- <style type="text/css" media="all">@import "fancy_style.css";</style> -->
<script language="JavaScript" type="text/javascript" src="https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/js/styleswitcher.js"></script> 
<style type="text/css">
<!--
div.figure {float:none;width=25%;} 
div.figure p {test-aligh: center;font-style:italic;}
div.figureL {float:left;width=50%; margin:1.5em;padding:4px 4px 4px 0px;} 
div.figureL p {test-aligh: center;font-style:italic;}
div.figureR {float:right;width=50%;margin:1.5em;padding:4px 4px 4px 0px;} 
div.figureR p {test-aligh: center;font-style:italic;}

a:link {color: #0000CC; text-decoration:none}
a:visited {color: #0000CC; text-decoration:none}
a:hover {color: green; text-decoration:underline; background:#F9EDED}
a:active {color: red; text-decoration:none}

.style1 {
	color: #CC0000;
	font-weight: bold;
}
.style3 {
	color: #CC0000;
	font-weight: bold;
}
.style4 {color: #CCCCCC}
.style7 {font-family: "Courier New", Courier, mono}
.style8 {
	font-family: Arial, Helvetica, sans-serif;
	color: #810000;
}
.style9 {
	color: #3333CC;
	font-weight: bold;
}
.styleArial {
	font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;
}
.style23 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#F0F0F0;
}
.style11 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	
}

.style22 {color: #663366; font-weight: bold; }

.style10 {
	font-family: "Courier New", Courier, mono;
	color: #000000;
	background-color:#F0F0F0;
}

.style24 {
	font-family: "Courier New", Courier, mono;
	color: #0000FF;
	font-size:small;
}
.style25 {
	font-family: "Courier New", Courier, mono;
	color: #0000FF;
	background-color:#FFFC9A;
	font-size:small;
}
.style15 {font-family: "Courier New", Courier, mono; color: #339933; font-weight: bold; background-color:#F0F0F0; }
.style100 {
	background-color:#FFFC9A;
}



.style19 {color: #339933;
	font-weight: bold;}

.style42 {color: #0000FF; font-weight: bold; font-family: "Courier New", Courier, mono;  background-color:#F0F0F0;}
.style102 {color: #CC0000;
	font-weight: bold;
}
.style12 {color: #CC0000;
	font-weight: bold;
}
.style31 {color: #336699; font-weight: bold; }
.styleArial1 {	font-family: Arial, Helvetica, sans-serif;
	font-size:11.0pt;
}
.styleArial1 {	font-family: Arial, Helvetica, sans-serif;font-size:11.0pt;
}
.style242 {color: #009966;
	font-weight: bold;
}
.style13 {	color: #CC0000;
	font-weight: bold;
}
.style13 {	color: #CC0000;
	font-weight: bold;
}
.style1021 {color: #CC0000;
	font-weight: bold;
}
.style221 {color: #663366; font-weight: bold; }
.style221 {color: #990099;
	font-weight: bold;
}
.style41 {color: #CC0000;
	font-weight: bold;
}
.style44 {font-family: "Courier New", Courier, mono}
.style91 {color: #339900;
	font-weight: bold;
}

-->
</style>
</head>

<body>
<h1 align="center"><a name="lecture38" id="lecture38"></a>Lecture 38&mdash;Monday, April 16, 2012</h1>
<h2>Outline of lecture</h2>
<ul>
  <li><a href="lecture38.htm#multinomial">Multinomial data</a>
    <ul>
      <li><a href="lecture38.htm#connection">A connection between  multinomial and Poisson distributions</a></li>
    </ul>
  </li>
  <li><a href="lecture38.htm#types">Types of  multinomial models</a></li>
  <li><a href="lecture38.htm#baseline">Baseline category logit model</a>
<ul>
      <li><a href="lecture38.htm#likelihood">Likelihood expression for the baseline category logit model</a></li>
      <li><a href="lecture38.htm#alternatives">Alternatives to the baseline category logit model</a></li>
    </ul>
  </li>
  <li><a href="lecture38.htm#fitting">Fitting a multinomial model as a Poisson model</a></li>
</ul>
<h2 align="left"><strong><a name="multinomial" id="multinomial"></a>Multinomial data</strong></h2>
<p>The multinomial distribution extends the binomial distribution to the case where there are more than two categories. If <em>Y</em> ~ binomial(<em>n</em>, <em>p</em>) then <em>Y</em> has the following probability mass function.</p>
<p align="center"><img src="../../images/lectures/lecture38/binomial.gif" width="363" height="122" alt="binomial"></p>
<p><img src="../../images/lectures/lecture38/binomialcoef.gif" alt="binomial coefficient" width="55" height="65" align="absmiddle"> is called the binomial coefficient and is defined as shown. If we let <em>Y</em><sub>1</sub> denote the number of successes and <em>Y</em><sub>2</sub> the number of failures with probabilities <em>p</em><sub>1</sub> and <em>p</em><sub>2</sub>, then an equivalent way to write the binomial probability mass function is the following.</p>
<p align="center"><img src="../../images/lectures/lecture38/binomial2.gif" width="278" height="57" alt="binomial"></p>
<p>where <em>k</em><sub>1</sub> + <em>k</em><sub>2</sub> = <em>n</em> and <em>p</em><sub>1</sub> + <em>p</em><sub>2</sub> = 1. </p>
<p>The multinomial model for a random variable <em>Y</em> with <em>m</em> categories is an obvious generalization of this last equation. Suppose <img src="../../images/lectures/lecture38/Yvector.gif" alt="Y" width="188" height="43" align="absmiddle"> is a multinomial random variable where <em>Y</em><sub>1</sub>, <em>Y</em><sub>2</sub>, &hellip;, <em>Y</em><sub>m</sub> are the frequencies of the  <em>m</em> categories. The multinomial probability mass function with parameters <em>n</em>,  <em>p</em><sub>1</sub>, <em>p</em><sub>2</sub>, &hellip; , <em>p</em><sub>m</sub> is the following.</p>
<p align="center"><img src="../../images/lectures/lecture38/multinomial.gif" width="532" height="140" alt="multinomial"></p>
<p>where <img src="../../images/lectures/lecture38/sumofk.gif" alt="sum of k equals n" width="75" height="58" align="absmiddle"> and <img src="../../images/lectures/lecture38/sumofp.gif" alt="sum of p equals 1" width="73" height="58" align="absmiddle">. The term multiplying the probabilities is the called the multinomial coefficient and is defined as shown.</p>
<h3><a name="connection"></a>A connection between    multinomial and Poisson distributions</h3>
<p>There's a useful connection between the Poisson and multinomial distributions that allows one  to fit regression models to multinomial data by assuming  that the individual counts have separate Poisson distributions. This forms the basis for the classical statistical approach called the loglinear model. </p>
<blockquote>
  <p>Suppose <em>Y</em><sub>1</sub>, <em>Y</em><sub>2</sub>, &hellip;, <em>Y</em><sub>m</sub> are independent Poisson random variables with parameters &lambda;<sub>1</sub>, &lambda;<sub>2</sub>, &hellip;, &lambda;<sub>m</sub>. If we  add the constraint that these <em>m</em> Poisson random variables must sum to a constant <em>n</em>, <img src="../../images/lectures/lecture38/sumofy.gif" alt="sum of y equals n" width="75" height="58" align="absmiddle">, then  it follows that the conditional joint distribution of <em>Y</em><sub>1</sub>, <em>Y</em><sub>2</sub>, &hellip;, <em>Y</em><sub>m</sub> given <em>n</em> is multinomial.</p>
</blockquote>
<p>It is easy to show that the sum of <em>m</em> independent Poisson random variables also has a Poisson distribution with parameter<img src="../../images/lectures/lecture38/sumoflambda.gif" alt="sum of lambda" width="78" height="58" align="absmiddle">. Using this fact we can write the following.</p>
<blockquote>
  <blockquote>
    <p>	<img src="../../images/lectures/lecture38/multpoisson1.gif" width="343" height="63" alt="multinomial poisson 1"><br>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../../images/lectures/lecture38/multpoisson2.gif" width="408" height="117" alt="multinomial poisson"><br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../../images/lectures/lecture38/multpoisson3.gif" width="252" height="125" alt="multinomial poisson 3"><br>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../../images/lectures/lecture38/multpoisson4.gif" width="437" height="73" alt="multinomial poisson 4"><br>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="../../images/lectures/lecture38/multpoisson5.gif" width="233" height="57" alt="multinomial poisson 5"></p>
  </blockquote>
</blockquote>
<p>where <img src="../../images/lectures/lecture38/sumofk.gif" alt="sum of k equals n" width="75" height="58" align="absmiddle">. Hence the conditional distribution is multinomial. The upstart is that multinomial regression models can be fit as Poisson regression models using maximum likelihood and we will obtain the same parameter estimates. As we'll see the Poisson approach requires estimating a lot of uninteresting auxiliary parameters that makes the this approach somewhat unwieldy. The advantage is that all the tools  to account for observational heterogeneity that are available for Poisson models can be applied to the multinomial setting, even if such tools are not currently available for multinomial models per se.</p>
<h2><a name="types"></a>Types of multinomial models</h2>
<p>There are three standard multinomial models that  are appropriate for different kinds of multinomial data.</p>
<ol>
  <li><strong>Baseline category logit model.</strong> This approach is appropriate for nominal multinomial data in which the categories are purely labels. A nominal variable's values  serve to identify membership in specific categories but have no other meaning.</li>
  <li><strong>Cumulative odds logit model.</strong> This approach can be appropriate for multinomial data in which the categories are ordinal. With ordinal categorical data  the categories have a natural order. Examples include the following:
    <ol type="a">
      <li>Medical diagnoses such as &quot;worse&quot;, &quot;no change&quot;, &quot;better&quot;</li>
      <li>Likert scale categories such as &quot;strongly disagree&quot;, &quot;disagree&quot;, &quot;neutral&quot;, &quot;agree&quot;, &quot;strongly agree&quot;</li>
      <li>Braun-Blanquet and&nbsp;Daubenmire cover classes in botany</li>
    </ol>
  </li>
</ol>
<blockquote>
  <p>Ordinal data may derive from an underlying unobserved continuous scale (often viewed as representing a latent variable) that is difficult to record. Although ordinal categorical data are ordered a precise notion of distance is not well-defined. Thus we can say that one category is greater than another but not how much greater it is or even if the spacings of the different categories are the same.</p>
</blockquote>
<ol start="3">
  <li><strong>Conditional logit model</strong> (also called a discrete choice model). These are often used in business or advertising but have seen some use in describing resource allocation in animals. The discrete choice model is defined not by the nature of the categories but by the kind of information we have about those categories  and  about the individual who chooses a category. The set of  categories may change for each observation. What each observation has in common is a set of covariates that describe  the different categories. There may be  additional covariates that describe the chooser, the individual making the choice.
    <p>In the discrete choice model we have predictors that describe the choices and additional descriptors that describe the chooser. In the baseline category and cumulative odds logit models we only have predictors that characterize the unit being categorized. A recent UNC graduate used a  discrete choice model  to describe the movement patterns of red cockaded woodpeckers from their nest tree. The categories were the possible flight paths a bird could take from its nest (which are different for  birds at  different nests). Each flight path was characterized by the amount of habitat of a specific type that it traversed. Additional information was available about the choosers: sex, age, size, etc. The goal was to determine what factors affected bird movement.</p>
  </li>
</ol>
<h2><a name="baseline"></a>Baseline category logit model</h2>
<p>The baseline category logit model  is also referred to as a multinomial logit model and polytomous logistic regression. As an illustration suppose a response variable <em>Y</em> has three categories 0, 1, and 2 and we have a single categorical predictor <em>X</em> with two categories 0 and 1. Our data can be organized in the form of a contingency table such as the one shown below.</p>
<p align="center"><img src="../../images/lectures/lecture38/data.gif" width="183" height="137" alt="data"></p>
<p>If we only had two categories, say <em>Y</em> = 0 and <em>Y</em> = 1, we could construct the following odds directly from the above table.</p>
<ul>
  <li>Odds of <em>Y</em> = 1 versus <em>Y</em> = 0 when<em> X </em>= 0: <img src="../../images/lectures/lecture38/odds1.gif" alt="odds 1" width="40" height="30" align="absmiddle"></li>
  <li>Odds of <em>Y</em> = 1 versus <em>Y</em> = 0 when <em>X</em> = 1: <img src="../../images/lectures/lecture38/odds2.gif" alt="odds 2" width="50" height="30" align="absmiddle"></li>
</ul>
<p>Thus the odds ratio of category 1 versus category 2 for <em>X</em> = 1 versus <em>X</em> = 0 is the following.</p>
<p align="center"><img src="../../images/lectures/lecture38/odds&#32;ratio.gif" width="423" height="58" alt="odds ratio"></p>
<p>Alternatively we could set this up as a logistic regression model.</p>
<p align="center"><img src="../../images/lectures/lecture38/logodds.gif" width="477" height="67" alt="log odds"></p>
<p>from which  the desired odds ratio is exp(&beta;<sub>1</sub>).</p>
<p>With three categories the situation is  only slightly more complicated. We  can choose one category as a reference category and construct log odds models that take the same form as in the two category case. With <em>Y</em> = 0 as the reference (baseline) group, we obtain  the following log odds expression for <em>Y</em> = 1.</p>
<p align="center"><img src="../../images/lectures/lecture38/logodds1.gif" width="250" height="67" alt="log odds 1"></p>
<p>For <em>Y</em> = 2 we have the following.</p>
<p align="center"><img src="../../images/lectures/lecture38/logodds2.gif" width="252" height="67" alt="log odds 2"></p>
<p>Observe that each new log odds comparison generates a different set of regression coefficients, so response variables with many categories will generate a lot of parameters. With three categories, two log odds expressions are all we need because we can derive any other log odds comparisons from these two. For instance to compare <em>Y</em> = 2 against <em>Y</em> = 1 we proceed as follows.</p>
<p align="center"><img src="../../images/lectures/lecture38/logodds3.gif" width="687" height="217" alt="log odds 3"></p>
<p>The only complication in what we've done is that technically these aren't log odds. An odds is a ratio of the probability in favor of an outcome versus the probability against that outcome. In the above expressions  the event  in the denominator is not the complement of the event in the numerator. Thus these are better thought of as &quot;odds-like&quot; expressions. In some disciplines they're referred to as risk ratios. With these same caveats, if <em>X</em> is a dichotomous random variable coded 0 and 1 then exp(&beta;<sub>11</sub>) and exp(&beta;<sub>12</sub>) have &quot;odds ratio&quot; interpretations. In general if the denominator is chosen judiciously so that it represents a group that forms a natural reference group for comparisons then the baseline logit model will return  probability ratios against an outcome of interest.  </p>
<h3><a name="likelihood"></a>Likelihood expression for the baseline category logit model</h3>
<p>For our simple example where <em>Y</em> = 0, 1, or 2, we can write down the conditional probabilities for <em>Y </em>= 1 and <em>Y</em> = 2 by exponentiating the two log odds expressions.</p>
<p align="center"><img src="../../images/lectures/lecture38/prob1.gif" width="388" height="102" alt="prob 1"></p>
<p align="center"><img src="../../images/lectures/lecture38/prob2.gif" width="392" height="102" alt="prob 2"></p>
<p>Because conditional probabilities must sum to 1 we  obtain the following expression for <img src="../../images/lectures/lecture38/prob0.gif" alt="prob 0" width="98" height="33" align="absmiddle">.</p>
<p align="center"><img src="../../images/lectures/lecture38/prob0a.gif" width="602" height="68" alt="prob 0"></p>
<p>Grouping the terms involving <img src="../../images/lectures/lecture38/prob0.gif" alt="prob 0" width="98" height="33" align="absmiddle"> together and solving yields an expression for <img src="../../images/lectures/lecture38/prob0.gif" alt="prob 0" width="98" height="33" align="absmiddle"> that only involves the regression parameters.</p>
<p align="center"><img src="../../images/lectures/lecture38/prob0b.gif" width="602" height="130" alt="prob 0"></p>
<p>Plugging this into the formulas above we obtain expressions for the probabilities of <em>Y</em> = 1 and <em>Y</em> = 2.</p>
<p align="center"><img src="../../images/lectures/lecture38/prob1a.gif" width="413" height="62" alt="prob 1"></p>
<p align="center"><img src="../../images/lectures/lecture38/prob2a.gif" width="417" height="62" alt="prob 2"></p>
<p>Let <em>i</em> = 1, 2, &hellip; , <em>n</em> denote the subjects. For subject <em>i</em> define the following dummy variables.</p>
<p align="center"><img src="../../images/lectures/lecture38/yi0.gif" width="577" height="72" alt="yi0"></p>
<p>Using these  we can write down the  likelihood for the baseline logit model.</p>
<p align="center"><img src="../../images/lectures/lecture38/likelihood.gif" width="618" height="270" alt="likelihood"></p>
<p>From this we can obtain maximum likelihood estimates of the baseline category logit parameters, likelihood ratio and Wald tests for individual parameters, and AIC for model comparison.</p>
<h3><a name="alternatives"></a>Alternatives to the baseline category logit model</h3>
<p>An obvious alternative to fitting the baseline category logit model is to fit separate logistic regressions using only two categories at a time. Because the likelihoods for these two approaches differ so will the parameter estimates (although in the case of one dichotomous predictor the two approaches give the same estimates). In general  the estimates one gets doing separate logistic regressions are less efficient (they tend to have larger standard errors). The usual recommendation is that if you choose to do separate logistic regressions then you should use as the reference category  the one that has the largest prevalences.</p>
<h2><a name="fitting"></a>Fitting a multinomial model as a Poisson model</h2>
<p>Suppose we have multinomial counts organized in a data frame <span class="style11">mydata</span> as follows.</p>
<p class="style11">y x z freq<br>
  1 A a&nbsp;&nbsp; n1<br>
  2 A a&nbsp;&nbsp; n2<br>
  3 A a&nbsp;&nbsp; n3<br>
  1 B a&nbsp;&nbsp; n4<br>
  2 B a&nbsp;&nbsp; n5<br>
  3 B a&nbsp;&nbsp; n6<br>
  1 A b&nbsp;&nbsp; n7<br>
  2 A b&nbsp;&nbsp; n8<br>
3 A b&nbsp;&nbsp; n9</p>
<p>Here <span class="style11">y</span> is a multinomial response variable with three categories, <span class="style11">x</span> and <span class="style11">z</span> are two dichotomous predictors, and <span class="style11">freq</span> records the number of times that each combination of <span class="style11">y</span>, <span class="style11">x</span>, and <span class="style11">z</span> occurred. Baseline category logit models can be fit with the <span class="style1">multinom</span> function from the <span class="style19">nnet</span> package. To fit a baseline category logit model  that is additive in <span class="style11">x</span> and <span class="style11">z</span> we would do the following.</p>
<p class="style11">multinom(y~x+z, weight=freq, data=mydata)</p>
<p>Any multinomial model with categorical predictors has a corresponding Poisson model that can be used to obtain equivalent tests of the effects of those predictors. Table 1 matches the R code of a multinomial model with the R code of its  corresponding Poisson model  (with the data argument left out). While the multinomial model uses the categorical variable as the response, the Poisson model uses the category counts as the response.</p>
<table border=0 align="center" cellpadding=2 cellspacing=2>
  <tr>
    <td width=400 valign=top  class="styleArial" style="padding-left: 72px; text-indent:-62px"><strong>Table 1 &nbsp;</strong> R code for multinomial models and equivalent Poisson models</td>
  </tr>
</table>
<table width="650" border="1" align="center" cellpadding=2 cellspacing=0 frame="box">
  <tr bgcolor="#F1D2D8">
    <td><strong>Model</strong></td>
    <td><div align="center"><strong>Predictor</strong></div></td>
    <td><div align="center"><strong>Multinomial model</strong> (.mult)</div></td>
    <td><div align="center"><strong>Poisson model</strong> (.pois)</div></td>
  </tr>
  <tr>
    <td><div align="center">1</div></td>
    <td><div align="center" class="style11">1</div></td>
    <td class="style11" style="padding-left: 30px; text-indent:-30px"><div align="left">multinom(y~1, weight=freq)</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">glm(freq~x+z+x:z+y, family=poisson)</div></td>
  </tr>
  <tr>
    <td><div align="center">2</div></td>
    <td><div align="center" class="style11">x</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">multinom(y~<span class="style100">x</span>, weight=freq)</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">glm(freq~x+z+x:z+y+<span class="style100">y:x</span>, family=poisson)</div></td>
  </tr>
  <tr>
    <td><div align="center">3</div></td>
    <td><div align="center" class="style11">x+z</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">multinom(y~<span class="style100">x+z</span>, weight=freq)</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">glm(freq~x+z+x:z+y+<span class="style100">y:x+y:z</span>, family=poisson)</div></td>
  </tr>
  <tr>
    <td><div align="center">4</div></td>
    <td><div align="center" class="style11">x*z</div></td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px">multinom(y~<span class="style100">x*z</span>, weight=freq)</td>
    <td class="style11"style="padding-left: 30px; text-indent:-30px"><div align="left">glm(freq~x+z+x:z+y+<span class="style100">y:x+y:z+y:x:z</span>, family=poisson)</div></td>
  </tr>
</table>
<p>Notice that the Poisson model corresponding to the intercept-only multinomial model has four terms in it: the two predictors, <span class="style11">x </span>and<span class="style11"> z</span>, as well as their interaction, <span class="style11">x:z</span>, plus the multinomial response, <span class="style11">y</span>. Predictors added directly to the multinomial model get added to the Poisson model as interactions with the response variable <span class="style11">y</span>. The likelihood and AIC of the Poisson and multinomial models are quite different but we can obtain the same statistical tests with each. If we wish to test the significance of the <span class="style11">x</span> effect in the multinomial model we can carry out the following likelihood ratio test.</p>
<p class="style11">anova(model1.mult, model2.mult, test='Chisq')</p>
<p>To test the effect of <span class="style11">x</span> using  the Poisson models we need to test the significance of the <span class="style11">y:x</span> term in model 2.</p>
<p class="style11">anova(model1.pois, model2.pois, test='Chisq')</p>
<p>The differences in the deviances (log-likelihoods) in both the multinomial and Poisson frameworks are the same and yield the same test statistic. </p>
<p>One of the advantages of using the Poisson framework is that there are more tools for dealing with model violations. As we'll see one of the ways to assess lack of fit in a multinomial model is by comparing it to a saturated model. Lack of fit can arise from a violation of the one of the basic assumptions of the multinomial model (constant probabilities, independent trials)  leading to what's called overdispersion. A quick fix for this in the Poisson framework is to include random effects or alternatively to fit a quasi-Poisson model instead of a Poisson. In the multinomial framework correcting for observational heterogeneity  is much more difficult.</p>
<p align="center"><a href="../../index.html">Course Home Page</a> </p>
<hr align="center" width="75%">
<!--Standard footer follows -->
<p></p>
<table width="650" border="3" cellspacing="2" cellpadding="2" align=
"CENTER">
  <tr bgcolor="#CCCCCC">
    <td width="100%"><font size=-1>Jack Weiss<br>
          <i>Phone: </i>(919) 962-5930<br>
          <i>E-Mail:</i> jack_weiss@unc.edu<br>
          <i>Address: </i>Curriculum for the Environment and Ecology, Box 3275, University of North Carolina, Chapel Hill, 27599<br>
      Copyright &copy; 2012<br>
      Last Revised--April 21, 2012<br>
      URL: <a href="lecture38.htm#lecture38" target="_self">https://sakai.unc.edu/access/content/group/2842013b-58f5-4453-aa8d-3e01bacbfc3d/public/Ecol562_Spring2012/docs/lectures/lecture38.htm</a></font></td>
  </tr>
</table>
<p align="center">&nbsp;</p>
</body>
</html>
